
==================================================
FILE: EcoBridge_Project\build.gradle.kts
==================================================

plugins {
`java-library`
// [修正] 使用新的 Plugin ID 和最新版本
id("io.papermc.paperweight.userdev") version "2.0.0-beta.19"
// 快速启动服务端测试插件
id("xyz.jpenilla.run-paper") version "2.3.0"
// Shadow 插件
id("com.gradleup.shadow") version "9.3.1"
}
group = "top.ellan"
version = "1.0-SNAPSHOT"
java {
// 保持使用 Java 25 (开启 Vector API 必须)
toolchain.languageVersion.set(JavaLanguageVersion.of(25))
}
repositories {
mavenCentral()
maven("https://repo.papermc.io/repository/maven-public/")
maven("https://repo.extendedclip.com/content/repositories/placeholderapi/")
maven("https://repo.nightexpressdev.com/releases")
maven("https://jitpack.io")
maven("https://repo.lanink.cn/repository/maven-public/")
flatDir { dirs("libs") }
}
dependencies {
// 1. 核心开发环境
paperweight.paperDevBundle("1.21.11-R0.1-SNAPSHOT")
// 2. 外部插件依赖
compileOnly("me.clip:placeholderapi:2.11.6")
compileOnly("su.nightexpress.coinsengine:CoinsEngine:2.6.0")
compileOnly("su.nightexpress.nightcore:main:2.13.0")
compileOnly("cn.superiormc.ultimateshop:plugin:4.2.3")
compileOnly("com.github.luben:zstd-jni:1.5.6-2")
// 本地 libs
compileOnly(fileTree(mapOf("dir" to "libs", "include" to listOf("*.jar"))))
// 3. 知识提取/数据处理库
implementation(platform("com.fasterxml.jackson:jackson-bom:2.17.0"))
implementation("com.fasterxml.jackson.core:jackson-databind")
implementation("com.fasterxml.jackson.core:jackson-core")
implementation("com.fasterxml.jackson.core:jackson-annotations")
implementation("redis.clients:jedis:5.2.0")
implementation("com.zaxxer:HikariCP:7.0.2")
implementation("com.github.ben-manes.caffeine:caffeine:3.2.3")
}
tasks {
compileJava {
options.encoding = "UTF-8"
// [必要修改] 必须设置为 25 以匹配 toolchain 并支持 Vector API
options.release.set(25)
// [必要修改] 开启预览特性和 Vector 孵化模块
options.compilerArgs.addAll(listOf(
"--enable-preview",
"--add-modules=jdk.incubator.vector"
))
}
// [新增] 配置测试任务以支持预览特性
test {
jvmArgs(
"--enable-preview",
"--add-modules=jdk.incubator.vector"
)
}
processResources {
val props = mapOf("version" to version)
inputs.properties(props)
filteringCharset = "UTF-8"
filesMatching("plugin.yml") {
expand(props)
}
}
// ShadowJar 配置
named<com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar>("shadowJar") {
archiveClassifier.set("")
val prefix = "top.ellan.ecobridge.libs"
relocate("com.fasterxml.jackson", "$prefix.jackson")
relocate("com.zaxxer.hikari", "$prefix.hikari")
relocate("redis.clients", "$prefix.jedis")
relocate("org.apache.commons.pool2", "$prefix.commons.pool2")
relocate("org.json", "$prefix.json")
relocate("com.github.benmanes.caffeine", "$prefix.caffeine")
exclude("META-INF/*.SF", "META-INF/*.DSA", "META-INF/*.RSA")
exclude("META-INF/maven/**")
minimize {
exclude(dependency("com.zaxxer:HikariCP:.*"))
}
}
build {
dependsOn("shadowJar")
}
// [新增] 配置 runServer 任务以支持预览特性
named<xyz.jpenilla.runtask.task.AbstractRun>("runServer") {
jvmArgs(
"--enable-preview",
"--add-modules=jdk.incubator.vector"
)
}
}

==================================================
FILE: EcoBridge_Project\settings.gradle.kts
==================================================

pluginManagement {
repositories {
gradlePluginPortal()
mavenCentral()
maven("https://repo.papermc.io/repository/maven-public/")
}
}
rootProject.name = "EcoBridge"

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\EcoBridge.java
==================================================

package top.ellan.ecobridge;
import org.bukkit.Bukkit;
import org.bukkit.plugin.java.JavaPlugin;
import org.bukkit.scheduler.BukkitRunnable;
public class EcoBridge extends JavaPlugin {
private static EcoBridge instance;
private DatabaseManager databaseManager;
private PidController pidController;
private MarketManager marketManager;
private IntegrationManager integrationManager;
private WebManager webManager;
private PerformanceMonitor performanceMonitor;
private volatile boolean fullyInitialized = false;
@Override
public void onEnable() {
instance = this;
long startTime = System.currentTimeMillis();
getLogger().info("═══════════════════════════════════════════════");
getLogger().info("  EcoBridge - Java 25 Extreme Performance");
getLogger().info("  SIMD + FFM + VirtualThreads + SoA Layout");
getLogger().info("═══════════════════════════════════════════════");
try {
saveDefaultConfig();
initializeComponents();
pidController.reloadConfig();
databaseManager.initPool();
registerPlaceholderAPI();
registerCommands();
startSchedulers();
if (getConfig().getBoolean("monitoring.enabled", true)) {
performanceMonitor = new PerformanceMonitor(this, pidController);
getLogger().info("Performance monitoring enabled");
}
warmupCriticalPaths();
fullyInitialized = true;
long elapsedMs = System.currentTimeMillis() - startTime;
getLogger().info("═══════════════════════════════════════════════");
getLogger().info("  ✓ EcoBridge loaded successfully in " + elapsedMs + "ms");
getLogger().info("═══════════════════════════════════════════════");
} catch (Exception e) {
getLogger().severe("═══════════════════════════════════════════════");
getLogger().severe("  ✗ FATAL: Failed to initialize EcoBridge");
getLogger().severe("═══════════════════════════════════════════════");
e.printStackTrace();
emergencyShutdown();
Bukkit.getPluginManager().disablePlugin(this);
}
}
@Override
public void onDisable() {
getLogger().info("═══════════════════════════════════════════════");
getLogger().info("  Gracefully shutting down EcoBridge...");
getLogger().info("═══════════════════════════════════════════════");
fullyInitialized = false;
try {
if (performanceMonitor != null) {
getLogger().info("[1/7] Stopping performance monitor...");
performanceMonitor.shutdown();
}
if (pidController != null) {
getLogger().info("[2/7] 将 PID 内存数据推送至数据库队列...");
int dirty = pidController.getDirtyQueueSize();
if (dirty > 0) {
getLogger().info("  → " + dirty + " 条脏数据进入队列");
}
pidController.flushBuffer(true);
}
if (databaseManager != null) {
getLogger().info("[3/7] 等待数据库异步写入完成...");
waitForDatabaseManager(8000);
}
if (databaseManager != null) {
getLogger().info("[4/7] 关闭数据库连接池...");
databaseManager.closePool();
}
if (pidController != null) {
getLogger().info("[5/7] 释放堆外内存 Arena...");
pidController.close();
}
if (webManager != null) {
getLogger().info("[6/7] Shutting down WebManager...");
webManager.shutdown();
}
if (marketManager != null) {
getLogger().info("[7/7] Shutting down market manager...");
marketManager.shutdown();
}
instance = null;
getLogger().info("═══════════════════════════════════════════════");
getLogger().info("  ✓ EcoBridge shutdown complete");
getLogger().info("═══════════════════════════════════════════════");
} catch (Exception e) {
getLogger().severe("Error during shutdown: " + e.getMessage());
e.printStackTrace();
}
}
private void initializeComponents() {
getLogger().info("Initializing core components...");
this.databaseManager = new DatabaseManager(this);
getLogger().info("  ✓ DatabaseManager");
this.pidController = new PidController(this);
getLogger().info("  ✓ PidController");
this.marketManager = new MarketManager(this);
getLogger().info("  ✓ MarketManager");
this.integrationManager = new IntegrationManager(this);
getLogger().info("  ✓ IntegrationManager");
this.webManager = new WebManager(this);
getLogger().info("  ✓ WebManager");
}
private void registerPlaceholderAPI() {
if (Bukkit.getPluginManager().getPlugin("PlaceholderAPI") != null) {
new EcoBridgeExpansion(this).register();
getLogger().info("  ✓ PlaceholderAPI integration");
} else {
getLogger().warning("  ⚠ PlaceholderAPI not found (variables disabled)");
}
}
private void registerCommands() {
if (getCommand("ecobridge") != null) {
EcoBridgeCommand commandHandler = new EcoBridgeCommand(this);
getCommand("ecobridge").setExecutor(commandHandler);
getCommand("ecobridge").setTabCompleter(commandHandler);
getLogger().info("  ✓ Commands registered (/eb, /ecobridge)");
} else {
getLogger().severe("  ✗ Failed to register command! Check plugin.yml");
}
}
private void startSchedulers() {
getLogger().info("Starting schedulers...");
long mainInterval = getConfig().getLong("schedulers.main-loop.period", 1200L);
long mainDelay = getConfig().getLong("schedulers.main-loop.initial-delay", 1200L);
new BukkitRunnable() {
@Override
public void run() {
if (!fullyInitialized) return;
try {
integrationManager.collectDataAndCalculate();
pidController.flushBuffer(false);
marketManager.updateActivityFactor();
} catch (Exception e) {
getLogger().warning("[Scheduler] Main loop error: " + e.getMessage());
}
}
}.runTaskTimer(this, mainDelay, mainInterval);
getLogger().info("  ✓ Main loop: every " + (mainInterval / 20) + "s");
long economyInterval = getConfig().getLong("schedulers.economy-update.period", 36000L);
long economyDelay = getConfig().getLong("schedulers.economy-update.initial-delay", 100L);
new BukkitRunnable() {
@Override
public void run() {
if (!fullyInitialized) return;
try {
marketManager.updateEconomyMetrics();
} catch (Exception e) {
getLogger().warning("[Scheduler] Economy update error: " + e.getMessage());
}
}
}.runTaskTimerAsynchronously(this, economyDelay, economyInterval);
getLogger().info("  ✓ Economy update: every " + (economyInterval / 20 / 60) + "min");
long marketInterval = getConfig().getLong("schedulers.market-flux-update.period", 6000L);
long marketDelay = getConfig().getLong("schedulers.market-flux-update.initial-delay", 20L);
new BukkitRunnable() {
@Override
public void run() {
if (!fullyInitialized) return;
try {
marketManager.updateMarketFlux();
marketManager.updateHolidayCache();
} catch (Exception e) {
getLogger().warning("[Scheduler] Market flux error: " + e.getMessage());
}
}
}.runTaskTimerAsynchronously(this, marketDelay, marketInterval);
getLogger().info("  ✓ Market flux: every " + (marketInterval / 20 / 60) + "min");
long reportInterval = 1200L;
long reportDelay = 1200L;
new BukkitRunnable() {
@Override
public void run() {
if (!fullyInitialized) return;
try {
webManager.pushMetrics(marketManager.getInflation(), performanceMonitor.getCurrentStats());
} catch (Exception e) {
getLogger().warning("[Scheduler] Report push error: " + e.getMessage());
}
}
}.runTaskTimerAsynchronously(this, reportDelay, reportInterval);
getLogger().info("  ✓ Report sampling: every " + (reportInterval / 20) + "s");
}
private void warmupCriticalPaths() {
if (!getConfig().getBoolean("performance.memory-warmup", true)) return;
getLogger().info("Warming up critical paths...");
Thread.ofVirtual().start(() -> {
try {
int retries = 0;
while (!databaseManager.isInitialized() && retries++ < 50) {
Thread.sleep(100);
}
if (databaseManager.isInitialized()) {
integrationManager.syncShops();
getLogger().info("  ✓ Shop data synced");
pidController.loadAllStates();
marketManager.updateMarketFlux();
marketManager.updateHolidayCache();
getLogger().info("  ✓ Market data initialized");
pidController.reloadConfig();
getLogger().info("  ✓ Warmup complete");
} else {
getLogger().warning("  ⚠ Database not ready, skipping warmup");
}
} catch (Exception e) {
getLogger().warning("Warmup error: " + e.getMessage());
}
});
}
private void waitForDatabaseManager(long timeoutMs) {
long startTime = System.currentTimeMillis();
while (System.currentTimeMillis() - startTime < timeoutMs) {
int pending = databaseManager.getPendingWritesCount();
if (pending == 0) {
getLogger().info("  ✓ 数据库队列已排空，所有数据已落盘");
return;
}
getLogger().info("  → 数据库队列剩余: " + pending + " 条");
try {
Thread.sleep(150);
} catch (InterruptedException e) {
break;
}
}
getLogger().warning("  ⚠ 数据库刷写超时（" + timeoutMs + "ms），可能丢失部分数据");
}
private void emergencyShutdown() {
try {
if (pidController != null) pidController.close();
if (marketManager != null) marketManager.shutdown();
if (databaseManager != null) databaseManager.closePool();
if (performanceMonitor != null) performanceMonitor.shutdown();
if (webManager != null) webManager.shutdown();
} catch (Exception ignored) {
}
}
public static EcoBridge getInstance() {
return instance;
}
public DatabaseManager getDatabaseManager() {
return databaseManager;
}
public PidController getPidController() {
return pidController;
}
public MarketManager getMarketManager() {
return marketManager;
}
public IntegrationManager getIntegrationManager() {
return integrationManager;
}
public PerformanceMonitor getPerformanceMonitor() {
return performanceMonitor;
}
public WebManager getWebManager() {
return webManager;
}
public boolean isFullyInitialized() {
return fullyInitialized;
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\EcoBridgeCommand.java
==================================================

package top.ellan.ecobridge;
import net.kyori.adventure.text.minimessage.MiniMessage;
import org.bukkit.Bukkit;
import org.bukkit.command.Command;
import org.bukkit.command.CommandExecutor;
import org.bukkit.command.CommandSender;
import org.bukkit.command.TabCompleter;
import org.bukkit.entity.Player;
import org.jetbrains.annotations.NotNull;
import org.jetbrains.annotations.Nullable;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.Random;
import java.util.stream.Collectors;
public class EcoBridgeCommand implements CommandExecutor, TabCompleter {
private final EcoBridge plugin;
private final MiniMessage mm = MiniMessage.miniMessage();
public EcoBridgeCommand(EcoBridge plugin) {
this.plugin = plugin;
}
private void msg(CommandSender sender, String message) {
sender.sendMessage(mm.deserialize(message));
}
@Override
public boolean onCommand(@NotNull CommandSender sender, @NotNull Command command,
@NotNull String label, @NotNull String[] args) {
if (!sender.hasPermission("ecobridge.admin")) {
msg(sender, "<red>❌ 你没有权限执行此操作。");
return true;
}
if (args.length == 0 || args[0].equalsIgnoreCase("help")) {
sendHelp(sender);
return true;
}
String sub = args[0].toLowerCase();
switch (sub) {
case "reload" -> handleReload(sender);
case "check" -> handleCheck(sender, args);
case "perf" -> handlePerf(sender);
case "save" -> handleSave(sender);
case "inspect" -> handleInspect(sender, args);
case "simd" -> handleSIMD(sender);
case "health" -> handleHealth(sender);
case "benchmark" -> handleBenchmark(sender, args);
default -> sendHelp(sender);
}
return true;
}
private void sendHelp(CommandSender sender) {
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:gold:yellow><bold>EcoBridge</gradient> <dark_gray>» <gray>v" +
plugin.getPluginMeta().getVersion());
msg(sender, "");
msg(sender, " <yellow>基础维护:");
msg(sender, "  <gold>/eb reload <dark_gray>• <gray>热重载配置、商店、市场、PID 参数 ");
msg(sender, "  <gold>/eb check [玩家] <dark_gray>• <gray>分析指定玩家的经济因子");
msg(sender, "  <gold>/eb inspect <ID> <dark_gray>• <gray>实时审查物品 PID 运行数据");
msg(sender, "  <gold>/eb save <dark_gray>• <gray>强制刷写脏数据至数据库");
msg(sender, "");
msg(sender, " <yellow>高级诊断:");
msg(sender, "  <gold>/eb perf <dark_gray>• <gray>查看内存、TPS 及缓存统计");
msg(sender, "  <gold>/eb simd <dark_gray>• <gray>CPU 向量化指令集兼容性诊断");
msg(sender, "  <gold>/eb health <dark_gray>• <gray>系统模块健康度自动化检查");
msg(sender, "  <gold>/eb benchmark confirm <dark_gray>• <gray>执行 5M 次 PID 压力基准测试");
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleReload(CommandSender sender) {
msg(sender, "<yellow>⟳ 正在异步重载全系统模块（含 PID 参数）...");
Bukkit.getScheduler().runTaskAsynchronously(plugin, () -> {
long start = System.currentTimeMillis();
try {
plugin.reloadConfig();
plugin.getPidController().reloadConfig();
plugin.getIntegrationManager().syncShops();
plugin.getMarketManager().updateHolidayCache();
plugin.getMarketManager().updateEconomyMetrics();
plugin.getMarketManager().updateMarketFlux();
msg(sender, "<green>✓ 重载成功! 耗时: <white>" + (System.currentTimeMillis() - start) + "ms");
} catch (Exception e) {
msg(sender, "<red>✗ 重载失败: " + e.getMessage());
e.printStackTrace();
}
});
}
private void handlePerf(CommandSender sender) {
Runtime rt = Runtime.getRuntime();
double usedMem = (rt.totalMemory() - rt.freeMemory()) / 1048576.0;
double maxMem = rt.maxMemory() / 1048576.0;
double tps = Bukkit.getTPS()[0];
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:gold:yellow>性能实时监控</gradient>");
msg(sender, " <gray>控制器缓存: <aqua>" + plugin.getPidController().getCacheSize() + " <dark_gray>items");
msg(sender, " <gray>待刷写数据: <red>" + plugin.getPidController().getDirtyQueueSize() + " <dark_gray>pending");
msg(sender, " <gray>TPS (1m): " + (tps > 18 ? "<green>" : "<red>") + String.format("%.2f", tps));
msg(sender, String.format(" <gray>JVM 内存: <aqua>%.0fMB <dark_gray>/ <gray>%.0fMB", usedMem, maxMem));
msg(sender, " <gray>活跃线程: <white>" + Thread.activeCount());
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleSIMD(CommandSender sender) {
msg(sender, "<yellow>⟳ 正在探测 CPU 指令集兼容性...");
var species = jdk.incubator.vector.DoubleVector.SPECIES_PREFERRED;
int lanes = species.length();
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:aqua:blue>SIMD 诊断报告</gradient>");
msg(sender, " <gray>Preferred Species: <white>" + species);
msg(sender, " <gray>Vector Width: <gold>" + (lanes * 64) + "-bit");
msg(sender, " <gray>并行通道数: <green>" + lanes + " <dark_gray>(doubles per cycle)");
String tech = lanes >= 8 ? "AVX-512" : lanes >= 4 ? "AVX2/AVX" : "SSE/Neon";
msg(sender, " <gray>硬件加速级别: <yellow>" + tech);
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleHealth(CommandSender sender) {
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:green:lime>系统健康普查</gradient>");
boolean db = plugin.getDatabaseManager().getDataSource() != null &&
!plugin.getDatabaseManager().getDataSource().isClosed();
msg(sender, " <gray>数据库连接: " + (db ? "<green>健康" : "<red>离线"));
int shops = plugin.getIntegrationManager().getMonitoredItems().size();
msg(sender, " <gray>商店映射: <white>" + (shops > 0 ? "<green>已挂载 (" + shops + ")" : "<red>无数据"));
int pidItems = plugin.getPidController().getCacheSize();
msg(sender, " <gray>计算内核: " + (pidItems > 0 ? "<green>活动中" : "<yellow>空闲"));
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleInspect(CommandSender sender, String[] args) {
if (args.length < 2) {
msg(sender, "<red>用法: /eb inspect <shopId_productId>");
return;
}
String itemId = args[1];
var state = plugin.getPidController().inspectState(itemId);
if (state == null) {
msg(sender, "<red>✗ 物品 [<white>" + itemId + "<red>] 尚未进入 PID 缓存。");
return;
}
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:aqua:blue>PID 运行快照</gradient> <dark_gray>» <white>" + itemId);
msg(sender, String.format(" <gray>Integral (积分): <aqua>%.4f", state.integral()));
msg(sender, String.format(" <gray>Last Error (误差): <red>%.4f", state.lastError()));
msg(sender, String.format(" <gray>Lambda (系数): <green>%.5f", state.lastLambda()));
msg(sender, " <gray>最后更新: <white>" + ((System.currentTimeMillis() - state.updateTime()) / 1000) + "s 前");
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleCheck(CommandSender sender, String[] args) {
Player target = (args.length > 1) ? Bukkit.getPlayer(args[1]) : (sender instanceof Player p ? p : null);
if (target == null) {
msg(sender, "<red>✗ 请指定一名在线玩家。");
return;
}
MarketManager mm = plugin.getMarketManager();
double p = mm.calculatePersonalFactor(target);
double f = mm.getMarketFlux();
double h = mm.getHolidayFactor();
double a = mm.getActivity();
double i = mm.getInflation();
double total = p * f * h * a * i;
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:gold:yellow>经济因子分析</gradient> <dark_gray>» <white>" + target.getName());
msg(sender, String.format(" <gray>个人/通胀: <aqua>%.2f <dark_gray>/ <gold>%.2f", p, i));
msg(sender, String.format(" <gray>环境/活跃: <light_purple>%.2f <dark_gray>/ <dark_aqua>%.2f", h, a));
msg(sender, String.format(" <gray>市场波动: <blue>%.2f", f));
msg(sender, "<yellow>➔ 最终全局倍率: <green><bold>" + String.format("%.4f", total));
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleBenchmark(CommandSender sender, String[] args) {
if (args.length < 2 || !args[1].equalsIgnoreCase("confirm")) {
msg(sender, "<yellow>⚠ 该操作将瞬时产生高负载。请输入 <gold>/eb benchmark confirm <yellow>确认。");
return;
}
msg(sender, "<aqua>正在启动 5,000,000 次 PID 模拟迭代压力测试...（异步执行）");
Bukkit.getScheduler().runTaskAsynchronously(plugin, () -> {
try {
PidController pid = plugin.getPidController();
Random rand = new Random();
int totalIterations = 5_000_000;
int batchSize = 4096;
long startNs = System.nanoTime();
int[] handles = new int[batchSize];
double[] volumes = new double[batchSize];
List<String> monitored = plugin.getIntegrationManager().getMonitoredItems();
if (monitored.isEmpty()) {
msg(sender, "<red>✗ 没有可用于基准测试的物品数据。");
return;
}
for (int i = 0; i < batchSize; i++) {
String id = monitored.get(i % monitored.size());
handles[i] = pid.getHandle(id);
volumes[i] = 800 + rand.nextDouble() * 400;
}
int batches = totalIterations / batchSize;
for (int b = 0; b < batches; b++) {
pid.calculateBatch(handles, volumes, batchSize);
}
long elapsedNs = System.nanoTime() - startNs;
double elapsedMs = elapsedNs / 1_000_000.0;
double opsPerSec = totalIterations / (elapsedNs / 1_000_000_000.0);
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:aqua:blue>Benchmark 结果</gradient>");
msg(sender, " <gray>总迭代次数: <white>" + totalIterations);
msg(sender, String.format(" <gray>耗时: <white>%.2f ms", elapsedMs));
msg(sender, String.format(" <gray>吞吐量: <gold>%.0f ops/s", opsPerSec));
msg(sender, " <gray>平均每批: <white>" + String.format("%.2f ms", elapsedMs / batches));
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
} catch (Exception e) {
msg(sender, "<red>✗ Benchmark 执行失败: " + e.getMessage());
e.printStackTrace();
}
});
}
private void handleSave(CommandSender sender) {
int dirty = plugin.getPidController().getDirtyQueueSize();
if (dirty == 0) {
msg(sender, "<gray>没有需要刷写的脏数据。");
return;
}
msg(sender, "<yellow>正在手动刷写 " + dirty + " 条数据...");
plugin.getPidController().flushBuffer(true);
msg(sender, "<green>数据已安全持久化至数据库。");
}
@Override
public @Nullable List<String> onTabComplete(@NotNull CommandSender sender, @NotNull Command command, @NotNull String label, @NotNull String[] args) {
if (args.length == 1) {
return filter(args[0], Arrays.asList("reload", "check", "inspect", "save", "perf", "simd", "health", "benchmark", "help"));
}
if (args.length == 2) {
if (args[0].equalsIgnoreCase("check")) return null;
if (args[0].equalsIgnoreCase("inspect")) return filter(args[1], plugin.getIntegrationManager().getMonitoredItems());
}
return Collections.emptyList();
}
private List<String> filter(String input, List<String> list) {
return list.stream().filter(s -> s.toLowerCase().startsWith(input.toLowerCase())).collect(Collectors.toList());
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\EcoBridgeExpansion.java
==================================================

package top.ellan.ecobridge;
import me.clip.placeholderapi.expansion.PlaceholderExpansion;
import org.bukkit.OfflinePlayer;
import org.jetbrains.annotations.NotNull;
import java.util.concurrent.ConcurrentHashMap;
public class EcoBridgeExpansion extends PlaceholderExpansion {
private final EcoBridge plugin;
private final ConcurrentHashMap<String, CachedValue> personalFactorCache = new ConcurrentHashMap<>();
private static final long CACHE_TTL_MS = 1000;
private long lastCacheCleanup = System.currentTimeMillis();
private static class CachedValue {
final double value;
final long timestamp;
CachedValue(double value) {
this.value = value;
this.timestamp = System.currentTimeMillis();
}
boolean isExpired() {
return System.currentTimeMillis() - timestamp > CACHE_TTL_MS;
}
}
public EcoBridgeExpansion(EcoBridge plugin) {
this.plugin = plugin;
}
@Override
public @NotNull String getIdentifier() {
return "eco";
}
@Override
public @NotNull String getAuthor() {
return "Ellan";
}
@Override
public @NotNull String getVersion() {
return "2.0.0";
}
@Override
public boolean persist() {
return true;
}
@Override
public String onRequest(OfflinePlayer player, @NotNull String params) {
if (!plugin.isEnabled()) return "Loading...";
MarketManager market = plugin.getMarketManager();
if (market == null) return "Error";
cleanupCache();
return switch (params.toLowerCase()) {
case "inflation" -> formatDecimal(market.getInflation(), 4);
case "inflation_raw" -> String.valueOf(market.getInflation());
case "inflation_percent" -> formatPercent(market.getInflation() - 1.0);
case "flux" -> formatDecimal(market.getMarketFlux(), 4);
case "flux_raw" -> String.valueOf(market.getMarketFlux());
case "activity" -> formatDecimal(market.getActivity(), 4);
case "activity_raw" -> String.valueOf(market.getActivity());
case "threshold" -> formatInteger(market.getCurrentThreshold());
case "threshold_raw" -> String.valueOf(market.getCurrentThreshold());
case "threshold_k" -> formatThousands(market.getCurrentThreshold());
case "holiday" -> formatDecimal(market.getHolidayFactor(), 2);
case "holiday_raw" -> String.valueOf(market.getHolidayFactor());
case "holiday_percent" -> formatPercent(market.getHolidayFactor() - 1.0);
case "personal" -> getPersonalFactor(player, market, 4);
case "personal_raw" -> getPersonalFactor(player, market, -1);
case "final", "final_all" -> getFinalFactor(player, market, 4);
case "final_raw", "final_all_raw" -> getFinalFactor(player, market, -1);
case "final_percent" -> {
double factor = calculateFinalFactor(player, market);
yield formatPercent(factor - 1.0);
}
case "perf_simd_active" -> String.valueOf(plugin.getPerformanceMonitor() != null);
case "perf_memory_used" -> {
Runtime rt = Runtime.getRuntime();
long usedMB = (rt.totalMemory() - rt.freeMemory()) / 1048576;
yield usedMB + "MB";
}
case "perf_memory_percent" -> {
Runtime rt = Runtime.getRuntime();
double percent = 100.0 * (rt.totalMemory() - rt.freeMemory()) / rt.maxMemory();
yield formatPercent(percent / 100.0);
}
default -> {
PidController pid = plugin.getPidController();
if (pid == null) yield "N/A";
if (params.startsWith("pid_")) {
String itemId = params.substring(4);
double lambda = pid.getLambdaByString(itemId);
yield formatDecimal(lambda, 5);
}
if (params.startsWith("pid_raw_")) {
String itemId = params.substring(8);
double lambda = pid.getLambdaByString(itemId);
yield String.valueOf(lambda);
}
yield null;
}
};
}
private void cleanupCache() {
long now = System.currentTimeMillis();
if (now - lastCacheCleanup > 5000) {
personalFactorCache.entrySet().removeIf(entry -> entry.getValue().isExpired());
lastCacheCleanup = now;
}
}
private String getPersonalFactor(OfflinePlayer player, MarketManager market, int decimals) {
if (player == null) return decimals < 0 ? "1.0" : "1.0000";
String uuid = player.getUniqueId().toString();
CachedValue cached = personalFactorCache.get(uuid);
if (cached != null && !cached.isExpired()) {
return decimals < 0 ? String.valueOf(cached.value) :
String.format("%." + decimals + "f", cached.value);
}
if (player.isOnline()) {
double factor = market.calculatePersonalFactor(player.getPlayer());
personalFactorCache.put(uuid, new CachedValue(factor));
return decimals < 0 ? String.valueOf(factor) :
String.format("%." + decimals + "f", factor);
}
return decimals < 0 ? "1.0" : "1.0000";
}
private String getFinalFactor(OfflinePlayer player, MarketManager market, int decimals) {
double factor = calculateFinalFactor(player, market);
return decimals < 0 ? String.valueOf(factor) :
String.format("%." + decimals + "f", factor);
}
private double calculateFinalFactor(OfflinePlayer player, MarketManager market) {
double personal = 1.0;
if (player != null && player.isOnline()) {
String uuid = player.getUniqueId().toString();
CachedValue cached = personalFactorCache.get(uuid);
if (cached != null && !cached.isExpired()) {
personal = cached.value;
} else {
personal = market.calculatePersonalFactor(player.getPlayer());
personalFactorCache.put(uuid, new CachedValue(personal));
}
}
return personal
* market.getMarketFlux()
* market.getHolidayFactor()
* market.getActivity()
* market.getInflation();
}
private String formatDecimal(double value, int decimals) {
return String.format("%." + decimals + "f", value);
}
private String formatInteger(double value) {
return String.format("%,.0f", value);
}
private String formatThousands(double value) {
if (value >= 1_000_000) {
return String.format("%.1fM", value / 1_000_000);
} else if (value >= 1_000) {
return String.format("%.1fK", value / 1_000);
} else {
return String.format("%.0f", value);
}
}
private String formatPercent(double ratio) {
return String.format("%.1f%%", ratio * 100);
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\FastSnapshotManager.java
==================================================

package top.ellan.ecobridge;
import com.github.luben.zstd.Zstd;
import org.bukkit.Bukkit;
import java.io.*;
import java.lang.foreign.Arena;
import java.lang.foreign.MemorySegment;
import java.lang.foreign.ValueLayout;
import java.nio.ByteBuffer;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.charset.StandardCharsets;
import java.nio.file.*;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.locks.LockSupport;
import java.util.function.Consumer;
import java.util.zip.CRC32;
public class FastSnapshotManager {
private final EcoBridge plugin;
private final Path dataDir;
private final BlockingQueue<DatabaseManager.PidDbSnapshot> writeQueue = new LinkedBlockingQueue<>(100000);
private final int flushThresholdItems;
private final int flushIntervalMs;
private final int compressionLevel;
private final AtomicBoolean running = new AtomicBoolean(true);
private Thread writerThread;
private static final String SNAPSHOT_EXT = ".zst";
private static final String INDEX_FILE = "latest_snapshot.id";
public FastSnapshotManager(EcoBridge plugin) {
this.plugin = plugin;
this.dataDir = Paths.get(plugin.getDataFolder().getAbsolutePath(), "snapshots");
try {
if (!Files.exists(dataDir)) Files.createDirectories(dataDir);
} catch (IOException e) {
throw new RuntimeException("Failed to create snapshot directory", e);
}
this.flushThresholdItems = plugin.getConfig().getInt("persistence.flush-items", 5000);
this.flushIntervalMs = plugin.getConfig().getInt("persistence.flush-interval-ms", 5000);
this.compressionLevel = plugin.getConfig().getInt("persistence.compression-level", 3);
startWriter();
}
private void startWriter() {
this.writerThread = Thread.ofVirtual()
.name("EcoBridge-SnapshotWriter")
.start(this::writerLoop);
}
private void writerLoop() {
ArrayList<DatabaseManager.PidDbSnapshot> buffer = new ArrayList<>(flushThresholdItems);
long lastFlushTime = System.currentTimeMillis();
while (running.get()) {
try {
DatabaseManager.PidDbSnapshot item = writeQueue.poll();
if (item != null) {
buffer.add(item);
while (buffer.size() < flushThresholdItems && (item = writeQueue.poll()) != null) {
buffer.add(item);
}
}
long now = System.currentTimeMillis();
boolean shouldFlush = !buffer.isEmpty() && (buffer.size() >= flushThresholdItems || (now - lastFlushTime > flushIntervalMs));
if (shouldFlush) {
flushToDisk(buffer);
buffer.clear();
lastFlushTime = now;
} else {
LockSupport.parkNanos(100_000_000);
}
} catch (Exception e) {
plugin.getLogger().severe("[Snapshot] Writer error: " + e.getMessage());
e.printStackTrace();
LockSupport.parkNanos(1_000_000_000);
}
}
if (!buffer.isEmpty()) {
flushToDisk(buffer);
}
}
private void flushToDisk(List<DatabaseManager.PidDbSnapshot> data) {
if (data.isEmpty()) return;
long startNs = System.nanoTime();
String filename = "pid_snapshot_" + System.currentTimeMillis() + SNAPSHOT_EXT;
Path targetFile = dataDir.resolve(filename);
try {
StringBuilder jsonBuilder = new StringBuilder(data.size() * 150);
jsonBuilder.append("[");
for (int i = 0; i < data.size(); i++) {
DatabaseManager.PidDbSnapshot s = data.get(i);
jsonBuilder.append("{\"i\":\"").append(escapeJson(s.itemId()))
.append("\",\"in\":").append(s.integral())
.append(",\"le\":").append(s.lastError())
.append(",\"ll\":").append(s.lastLambda())
.append(",\"ut\":").append(s.updateTime())
.append("}");
if (i < data.size() - 1) jsonBuilder.append(",");
}
jsonBuilder.append("]");
byte[] jsonBytes = jsonBuilder.toString().getBytes(StandardCharsets.UTF_8);
ByteBuffer srcBuf = ByteBuffer.allocateDirect(jsonBytes.length);
srcBuf.put(jsonBytes);
srcBuf.flip();
int maxCompressedSize = (int) Zstd.compressBound(jsonBytes.length);
ByteBuffer destBuf = ByteBuffer.allocateDirect(maxCompressedSize);
long compressedSize = Zstd.compressDirectByteBuffer(
destBuf, 0, maxCompressedSize,
srcBuf, 0, jsonBytes.length,
compressionLevel
);
try (FileChannel channel = FileChannel.open(targetFile,
StandardOpenOption.WRITE, StandardOpenOption.CREATE_NEW)) {
ByteBuffer header = ByteBuffer.allocate(12);
header.putInt(0x4E505344);
header.putInt(0x56313030);
header.putInt(jsonBytes.length);
header.flip();
channel.write(header);
destBuf.limit((int) compressedSize);
channel.write(destBuf);
}
updateLatestIndex(filename);
long elapsedMs = (System.nanoTime() - startNs) / 1_000_000;
plugin.getLogger().info(String.format(
"[Snapshot] Saved %d items (%.2f KB -> %.2f KB) in %dms (Ratio: %.2f%%)",
data.size(),
jsonBytes.length / 1024.0,
compressedSize / 1024.0,
elapsedMs,
(compressedSize * 100.0 / jsonBytes.length)
));
} catch (Exception e) {
plugin.getLogger().severe("[Snapshot] Flush failed: " + e.getMessage());
e.printStackTrace();
}
}
public void loadStates(Consumer<DatabaseManager.PidDbSnapshot> consumer) {
String latestFilename = readLatestIndex();
if (latestFilename == null) {
plugin.getLogger().info("[Snapshot] No previous snapshot found. Starting fresh.");
return;
}
Path snapshotFile = dataDir.resolve(latestFilename);
if (!Files.exists(snapshotFile)) {
plugin.getLogger().warning("[Snapshot] Index points to missing file: " + latestFilename);
return;
}
plugin.getLogger().info("[Snapshot] Loading from: " + latestFilename);
long startNs = System.nanoTime();
try (FileChannel channel = FileChannel.open(snapshotFile, StandardOpenOption.READ)) {
long fileSize = channel.size();
if (fileSize < 12) throw new IOException("File too small (corrupted header)");
MappedByteBuffer headerBuffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, 12);
int magic = headerBuffer.getInt();
int version = headerBuffer.getInt();
int uncompressedSize = headerBuffer.getInt();
if (magic != 0x4E505344) throw new IOException("Invalid magic number");
if (version != 0x56313030) throw new IOException("Unsupported version");
long compressedSize = fileSize - 12;
MappedByteBuffer compressedBuffer = channel.map(FileChannel.MapMode.READ_ONLY, 12, compressedSize);
ByteBuffer destBuffer = ByteBuffer.allocateDirect(uncompressedSize);
long size = Zstd.decompressDirectByteBuffer(
destBuffer, 0, uncompressedSize,
compressedBuffer, 0, compressedSize
);
if (size != uncompressedSize) throw new IOException("Decompression size mismatch");
destBuffer.flip();
byte[] jsonBytes = new byte[uncompressedSize];
destBuffer.get(jsonBytes);
String jsonStr = new String(jsonBytes, StandardCharsets.UTF_8);
int count = parseAndConsume(jsonStr, consumer);
long elapsedMs = (System.nanoTime() - startNs) / 1_000_000;
plugin.getLogger().info(String.format(
"[Snapshot] Loaded %d items in %dms (%.1f items/sec)",
count, elapsedMs, count * 1000.0 / Math.max(1, elapsedMs)
));
} catch (Exception e) {
plugin.getLogger().severe("[Snapshot] Failed to load snapshot: " + e.getMessage());
e.printStackTrace();
}
}
private int parseAndConsume(String json, Consumer<DatabaseManager.PidDbSnapshot> consumer) {
int count = 0;
int len = json.length();
int i = 1;
while (i < len) {
if (json.charAt(i) == ']') break;
if (json.charAt(i) == '{') {
String id = null;
double integral = 0, lastErr = 0, lastLam = 0;
long updateTime = 0;
int start = json.indexOf("\"i\":\"", i);
int end = json.indexOf("\"", start + 5);
if (start > 0 && end > 0) {
id = json.substring(start + 5, end);
}
start = json.indexOf("\"in\":", end);
end = json.indexOf(",", start);
if (start > 0 && end > 0) integral = Double.parseDouble(json.substring(start + 5, end));
start = json.indexOf("\"le\":", end);
end = json.indexOf(",", start);
if (start > 0 && end > 0) lastErr = Double.parseDouble(json.substring(start + 5, end));
start = json.indexOf("\"ll\":", end);
end = json.indexOf(",", start);
if (start > 0 && end > 0) lastLam = Double.parseDouble(json.substring(start + 5, end));
start = json.indexOf("\"ut\":", end);
end = json.indexOf("}", start);
if (start > 0 && end > 0) updateTime = Long.parseLong(json.substring(start + 5, end));
if (id != null) {
consumer.accept(new DatabaseManager.PidDbSnapshot(id, integral, lastErr, lastLam, updateTime));
count++;
}
i = end + 1;
} else {
i++;
}
}
return count;
}
public void saveSnapshot(DatabaseManager.PidDbSnapshot snapshot) {
writeQueue.offer(snapshot);
}
public void saveBatch(List<DatabaseManager.PidDbSnapshot> snapshots) {
writeQueue.addAll(snapshots);
}
private void updateLatestIndex(String filename) {
try {
Files.writeString(dataDir.resolve(INDEX_FILE), filename, StandardOpenOption.CREATE, StandardOpenOption.TRUNCATE_EXISTING);
} catch (IOException e) {
plugin.getLogger().warning("[Snapshot] Failed to update index: " + e.getMessage());
}
}
private String readLatestIndex() {
try {
if (Files.exists(dataDir.resolve(INDEX_FILE))) {
return Files.readString(dataDir.resolve(INDEX_FILE));
}
} catch (IOException e) {
}
return null;
}
private String escapeJson(String s) {
return s;
}
public void shutdown() {
running.set(false);
if (writerThread != null) {
LockSupport.unpark(writerThread);
try {
writerThread.join(5000);
} catch (InterruptedException e) {
Thread.currentThread().interrupt();
}
}
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\IntegrationManager.java
==================================================

package top.ellan.ecobridge;
import cn.superiormc.ultimateshop.api.ShopHelper;
import cn.superiormc.ultimateshop.managers.ConfigManager;
import cn.superiormc.ultimateshop.objects.ObjectShop;
import cn.superiormc.ultimateshop.objects.buttons.ObjectItem;
import cn.superiormc.ultimateshop.objects.caches.ObjectUseTimesCache;
import cn.superiormc.ultimateshop.utils.ItemUtil;
import org.bukkit.Bukkit;
import org.bukkit.inventory.ItemStack;
import java.util.*;
public class IntegrationManager {
public record TradeMetadata(
String rawId,
String displayName,
String shopTitle
) {}
private record ItemEntry(
String rawId,
int pidHandle,
ObjectItem item,
TradeMetadata metadata
) {}
private final EcoBridge plugin;
private volatile List<ItemEntry> activeEntries = Collections.emptyList();
private volatile List<String> monitoredIdCache = Collections.emptyList();
private final Map<Integer, Double> lastTotalVolumes = new HashMap<>(4096);
public IntegrationManager(EcoBridge plugin) {
this.plugin = plugin;
}
public List<TradeMetadata> getRecentTradesMetadata() {
final List<ItemEntry> current = this.activeEntries;
List<TradeMetadata> list = new ArrayList<>(current.size());
for (ItemEntry entry : current) {
list.add(entry.metadata());
}
return list;
}
public void collectDataAndCalculate() {
final List<ItemEntry> currentItems = this.activeEntries;
if (currentItems.isEmpty()) {
if (Bukkit.getPluginManager().isPluginEnabled("UltimateShop")) {
syncShops();
if (activeEntries.isEmpty()) return;
} else {
return;
}
}
final int size = currentItems.size();
int[] handles = new int[size];
double[] deltaVolumes = new double[size];
int count = 0;
for (int i = 0; i < size; i++) {
ItemEntry entry = currentItems.get(i);
try {
ObjectUseTimesCache cache = ShopHelper.getServerUseTimesCache(entry.item());
if (cache != null) {
double currentTotal = cache.getBuyUseTimes() + cache.getSellUseTimes();
double lastTotal = lastTotalVolumes.getOrDefault(entry.pidHandle(), currentTotal);
double delta = currentTotal - lastTotal;
lastTotalVolumes.put(entry.pidHandle(), currentTotal);
handles[count] = entry.pidHandle();
deltaVolumes[count] = delta;
count++;
}
} catch (Exception ignored) {
}
}
if (count == 0) return;
final int finalCount = count;
final int[] finalHandles = (count == size) ? handles : Arrays.copyOf(handles, count);
final double[] finalDeltas = (count == size) ? deltaVolumes : Arrays.copyOf(deltaVolumes, count);
if (plugin.getPidController() != null) {
plugin.getPidController().calculateBatch(finalHandles, finalDeltas, finalCount);
}
}
public synchronized void syncShops() {
if (!Bukkit.getPluginManager().isPluginEnabled("UltimateShop") ||
ConfigManager.configManager == null ||
ConfigManager.configManager.shopConfigs == null) {
return;
}
Map<String, ObjectShop> shopMap = ConfigManager.configManager.shopConfigs;
if (shopMap.isEmpty()) return;
List<ItemEntry> newEntries = new ArrayList<>(shopMap.size() * 10);
List<String> newIds = new ArrayList<>(shopMap.size() * 10);
PidController pidCtrl = plugin.getPidController();
if (pidCtrl == null) return;
for (Map.Entry<String, ObjectShop> entry : shopMap.entrySet()) {
String shopId = entry.getKey();
ObjectShop shop = entry.getValue();
if (shop == null) continue;
List<ObjectItem> productList = shop.getProductList();
if (productList == null) continue;
String shopTitle = shopId;
for (ObjectItem item : productList) {
String productId = item.getProduct();
if (productId == null || productId.isEmpty()) continue;
String rawId = shopId + "_" + productId;
int handle = pidCtrl.getHandle(rawId);
String prettyName = item.getDisplayName(null);
if (prettyName == null || prettyName.isEmpty()) {
try {
ItemStack displayItem = item.getDisplayItem(null);
prettyName = ItemUtil.getItemName(displayItem);
} catch (Exception e) {
prettyName = rawId;
}
}
TradeMetadata metadata = new TradeMetadata(rawId, prettyName, shopTitle);
newEntries.add(new ItemEntry(rawId, handle, item, metadata));
newIds.add(rawId);
ObjectUseTimesCache cache = ShopHelper.getServerUseTimesCache(item);
if (cache != null) {
double currentTotal = cache.getBuyUseTimes() + cache.getSellUseTimes();
lastTotalVolumes.put(handle, currentTotal);
}
}
}
this.activeEntries = newEntries;
this.monitoredIdCache = Collections.unmodifiableList(newIds);
plugin.getLogger().info("[Integration] Synced " + activeEntries.size() + " items from UltimateShop.");
}
public List<String> getMonitoredItems() {
return monitoredIdCache;
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\MarketManager.java
==================================================

package top.ellan.ecobridge;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.bukkit.Bukkit;
import org.bukkit.Statistic;
import org.bukkit.entity.Player;
import su.nightexpress.coinsengine.CoinsEnginePlugin;
import su.nightexpress.coinsengine.api.CoinsEngineAPI;
import su.nightexpress.coinsengine.api.currency.Currency;
import su.nightexpress.coinsengine.tops.TopEntry;
import su.nightexpress.coinsengine.tops.TopManager;
import java.net.URI;
import java.net.http.HttpClient;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.time.DayOfWeek;
import java.time.Duration;
import java.time.LocalDate;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicReference;
public class MarketManager {
private final EcoBridge plugin;
private final ExecutorService ioExecutor = Executors.newVirtualThreadPerTaskExecutor();
private final AtomicReference<Double> inflation = new AtomicReference<>(1.0);
private final AtomicReference<Double> marketFlux = new AtomicReference<>(1.0);
private final AtomicReference<Double> currentThreshold = new AtomicReference<>(100000.0);
private final AtomicReference<Double> activityFactor = new AtomicReference<>(1.0);
private final ConcurrentHashMap<String, Integer> holidayCache = new ConcurrentHashMap<>();
private final ConcurrentHashMap<UUID, Map.Entry<Integer, Long>> statCache = new ConcurrentHashMap<>();
private volatile long lastHolidayUpdate = 0;
private final HttpClient httpClient;
private final ObjectMapper jsonMapper = new ObjectMapper();
private CoinsEnginePlugin coinsEnginePlugin;
private Currency currency;
private static final double MIN_THRESH = 100000.0;
private static final double INF_WEIGHT = 0.3;
private static final double PERCENTILE = 0.15;
private static final String HOLIDAY_API_URL = "https:
public MarketManager(EcoBridge plugin) {
this.plugin = plugin;
this.httpClient = HttpClient.newBuilder()
.version(HttpClient.Version.HTTP_2)
.connectTimeout(Duration.ofSeconds(10))
.executor(ioExecutor)
.build();
setupCoinsEngine();
}
private void setupCoinsEngine() {
if (Bukkit.getPluginManager().isPluginEnabled("CoinsEngine") && CoinsEngineAPI.isLoaded()) {
this.coinsEnginePlugin = CoinsEngineAPI.plugin();
String currencyId = plugin.getConfig().getString("economy-settings.currency-id", "money");
this.currency = CoinsEngineAPI.getCurrency(currencyId);
if (this.currency != null) {
plugin.getLogger().info("[Market] Hooked into CoinsEngine. Currency: " + currencyId);
if (!coinsEnginePlugin.getTopManager().isPresent()) {
plugin.getLogger().warning("[Market] CoinsEngine 'Top' feature is disabled in config!");
plugin.getLogger().warning("[Market] Inflation calculation will be skipped.");
}
} else {
plugin.getLogger().warning("[Market] Currency '" + currencyId + "' not found in CoinsEngine!");
}
} else {
plugin.getLogger().warning("[Market] CoinsEngine plugin not found or API not loaded!");
}
}
public void updateEconomyMetrics() {
if (currency == null || coinsEnginePlugin == null) return;
ioExecutor.submit(() -> {
try {
Optional<TopManager> topManagerOpt = coinsEnginePlugin.getTopManager();
if (topManagerOpt.isEmpty()) return;
TopManager topManager = topManagerOpt.get();
List<TopEntry> entries = topManager.getTopEntries(currency);
if (entries.isEmpty()) return;
int totalPlayers = entries.size();
int thresholdIndex = (int) Math.floor(totalPlayers * PERCENTILE);
thresholdIndex = Math.max(0, Math.min(totalPlayers - 1, thresholdIndex));
TopEntry thresholdEntry = entries.get(thresholdIndex);
double threshold = Math.max(thresholdEntry.getBalance(), MIN_THRESH);
currentThreshold.set(threshold);
double ratio = Math.max(1.0, threshold / MIN_THRESH);
double newInflation = 1.0 + (Math.log(ratio) * INF_WEIGHT);
inflation.set(newInflation);
cleanupStatCache();
plugin.getLogger().info(String.format(
"[Market] Metrics updated via CoinsEngine: Players=%d, Thresh=%.0f, Inf=%.4f",
totalPlayers, threshold, newInflation
));
} catch (Exception e) {
plugin.getLogger().warning("[Market] Metrics update failed: " + e.getMessage());
}
});
}
public double calculatePersonalFactor(Player player) {
if (player.isOp()) return 1.0;
double minFactor = plugin.getConfig().getDouble("personal-factor.min-factor", 0.5);
double maxTax = plugin.getConfig().getDouble("personal-factor.rich.max-tax", 0.1);
double currentFactor = 1.0;
if (currency != null) {
double balance = CoinsEngineAPI.getBalance(player.getUniqueId(), currency);
double threshold = currentThreshold.get();
if (balance > threshold) {
double excess = balance - threshold;
double tax = Math.log10(excess + 10) * (maxTax / 10.0);
currentFactor += Math.min(tax, maxTax * 2);
}
}
int ticksPlayed = getCachedStatistic(player, Statistic.PLAY_ONE_MINUTE);
if (ticksPlayed > 0) {
double vetMax = plugin.getConfig().getDouble("personal-factor.veteran.max-discount", 0.05);
int vetHours = plugin.getConfig().getInt("personal-factor.veteran.threshold-hours", 100);
double discount = (double) ticksPlayed / (vetHours * 72000L) * vetMax;
currentFactor -= Math.min(discount, vetMax);
}
return Math.max(minFactor, currentFactor);
}
private int getCachedStatistic(Player player, Statistic stat) {
UUID uid = player.getUniqueId();
Map.Entry<Integer, Long> entry = statCache.get(uid);
long now = System.currentTimeMillis();
if (entry != null && (now - entry.getValue() < 300_000)) {
return entry.getKey();
}
if (Bukkit.isPrimaryThread()) {
int val = player.getStatistic(stat);
statCache.put(uid, Map.entry(val, now));
return val;
} else {
Bukkit.getScheduler().runTask(plugin, () -> {
if (player.isOnline()) {
statCache.put(uid, Map.entry(player.getStatistic(stat), System.currentTimeMillis()));
}
});
return entry != null ? entry.getKey() : 0;
}
}
private void cleanupStatCache() {
long now = System.currentTimeMillis();
statCache.entrySet().removeIf(e -> (now - e.getValue().getValue() > 600_000));
}
public void updateMarketFlux() {
long currentHour = System.currentTimeMillis() / 3600000L;
Random rng = new Random(currentHour + "Salt".hashCode());
double range = plugin.getConfig().getDouble("market-flux.normal-range", 0.05);
if (rng.nextDouble() < plugin.getConfig().getDouble("market-flux.event-chance", 0.1)) {
range = plugin.getConfig().getDouble("market-flux.event-range", 0.3);
}
double rawFlux = 1.0 + ((rng.nextDouble() * 2.0 - 1.0) * range);
marketFlux.set(Math.floor(rawFlux * inflation.get() * 10000) / 10000.0);
}
public void updateActivityFactor() {
Bukkit.getScheduler().runTask(plugin, () -> {
int online = Bukkit.getOnlinePlayers().size();
double tps = Bukkit.getTPS()[0];
ioExecutor.submit(() -> {
double base = plugin.getConfig().getDouble("activity.base", 1.0);
double impact = plugin.getConfig().getDouble("activity.player-impact", 0.001);
double factor = base + (online * impact);
double tpsLimit = plugin.getConfig().getDouble("activity.tps-limit", 18.0);
if (tps < tpsLimit) {
double penalty = (20.0 - tps) * plugin.getConfig().getDouble("activity.tps-weight", 0.05);
factor = Math.max(0.1, factor - penalty);
}
activityFactor.set(factor);
});
});
}
public void updateHolidayCache() {
if (System.currentTimeMillis() - lastHolidayUpdate < 86400000) return;
int year = LocalDate.now().getYear();
HttpRequest request = HttpRequest.newBuilder()
.uri(URI.create(HOLIDAY_API_URL + "?year=" + year))
.header("User-Agent", "EcoBridge/Paper")
.timeout(Duration.ofSeconds(5))
.GET()
.build();
httpClient.sendAsync(request, HttpResponse.BodyHandlers.ofString())
.thenAccept(res -> {
if (res.statusCode() == 200) {
try {
JsonNode root = jsonMapper.readTree(res.body());
if (root.path("data").isArray()) {
holidayCache.clear();
for (JsonNode node : root.get("data")) {
holidayCache.put(node.get("date").asText(), node.get("type").asInt());
}
lastHolidayUpdate = System.currentTimeMillis();
}
} catch (Exception ignored) {}
}
});
}
public double getHolidayFactor() {
String dateKey = LocalDate.now().toString();
Integer type = holidayCache.get(dateKey);
if (type != null) {
return switch (type) {
case 0 -> plugin.getConfig().getDouble("holidays.workday", 1.0);
case 1 -> plugin.getConfig().getDouble("holidays.weekend", 1.1);
case 2 -> plugin.getConfig().getDouble("holidays.holiday", 1.5);
default -> 1.0;
};
}
DayOfWeek day = LocalDate.now().getDayOfWeek();
return (day == DayOfWeek.SATURDAY || day == DayOfWeek.SUNDAY)
? plugin.getConfig().getDouble("holidays.weekend", 1.1)
: 1.0;
}
public void shutdown() {
ioExecutor.shutdownNow();
}
public double getInflation() { return inflation.get(); }
public double getMarketFlux() { return marketFlux.get(); }
public double getActivity() { return activityFactor.get(); }
public double getCurrentThreshold() { return currentThreshold.get(); }
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\PerformanceMonitor.java
==================================================

package top.ellan.ecobridge;
import jdk.incubator.vector.DoubleVector;
import jdk.incubator.vector.VectorSpecies;
import org.bukkit.Bukkit;
import org.bukkit.scheduler.BukkitTask;
import java.lang.management.*;
import java.util.List;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.LongAdder;
public class PerformanceMonitor {
private final EcoBridge plugin;
private final PidController pidController;
private final ScheduledExecutorService scheduler;
private BukkitTask syncCacheTask;
private final LongAdder totalCalculations = new LongAdder();
private final LongAdder simdCalculations = new LongAdder();
private final LongAdder scalarCalculations = new LongAdder();
private final LongAdder dbWrites = new LongAdder();
private final LongAdder dbReads = new LongAdder();
private final ConcurrentHashMap<String, PerformanceCounter> counters = new ConcurrentHashMap<>();
private final MemoryMXBean memoryBean = ManagementFactory.getMemoryMXBean();
private final ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();
private GarbageCollectorMXBean youngGC;
private GarbageCollectorMXBean oldGC;
private volatile double[] cachedTps = new double[]{20.0, 20.0, 20.0};
private volatile int cachedPlayerCount = 0;
private final int logInterval;
private volatile long simdBandwidth = 0;
private volatile int vectorLanes = 0;
public PerformanceMonitor(EcoBridge plugin, PidController pidController) {
this.plugin = plugin;
this.pidController = pidController;
this.logInterval = plugin.getConfig().getInt("monitoring.log-interval", 300);
detectGCBeans();
this.scheduler = Executors.newSingleThreadScheduledExecutor(
r -> Thread.ofVirtual().name("EcoBridge-Monitor").unstarted(r)
);
this.syncCacheTask = Bukkit.getScheduler().runTaskTimer(plugin, this::updateServerStateCache, 100L, 100L);
benchmarkSIMD();
startMonitoring();
}
private void updateServerStateCache() {
try {
double[] tps = Bukkit.getTPS();
if (tps != null) {
this.cachedTps = tps;
}
this.cachedPlayerCount = Bukkit.getOnlinePlayers().size();
} catch (Throwable ignored) {}
}
private void detectGCBeans() {
List<GarbageCollectorMXBean> gcBeans = ManagementFactory.getGarbageCollectorMXBeans();
for (GarbageCollectorMXBean bean : gcBeans) {
String name = bean.getName().toLowerCase();
if (name.contains("young") || name.contains("eden") || name.contains("copy") || name.contains("scavenge")) {
youngGC = bean;
} else if (name.contains("old") || name.contains("tenured") || name.contains("mark") || name.contains("global")) {
oldGC = bean;
} else if (name.contains("g1")) {
if (name.contains("young")) youngGC = bean; else oldGC = bean;
} else if (name.contains("shenandoah") || name.contains("zgc")) {
oldGC = bean;
}
}
}
private void benchmarkSIMD() {
Thread.ofVirtual().start(() -> {
try {
VectorSpecies<Double> species = DoubleVector.SPECIES_PREFERRED;
vectorLanes = species.length();
int size = 1024 * 1024;
double[] data = new double[size];
for (int i = 0; i < 50; i++) vectorAdd(data, species);
long startNs = System.nanoTime();
int iterations = 100;
for (int i = 0; i < iterations; i++) vectorAdd(data, species);
long elapsedNs = System.nanoTime() - startNs;
long bytesProcessed = (long) size * 8L * iterations;
double seconds = elapsedNs / 1e9;
simdBandwidth = (long) (bytesProcessed / seconds / 1e9);
plugin.getLogger().info(String.format("[Perf] SIMD Active: %s (%d lanes), BW: %d GB/s",
species, vectorLanes, simdBandwidth));
} catch (Throwable e) {
plugin.getLogger().warning("[Perf] SIMD unavailable: " + e.getMessage());
}
});
}
private void vectorAdd(double[] data, VectorSpecies<Double> species) {
int i = 0;
int bound = species.loopBound(data.length);
for (; i < bound; i += species.length()) {
DoubleVector.fromArray(species, data, i).add(1.0).intoArray(data, i);
}
}
private void startMonitoring() {
scheduler.scheduleAtFixedRate(this::logPerformanceReport, logInterval, logInterval, TimeUnit.SECONDS);
}
private void logPerformanceReport() {
try {
StringBuilder report = new StringBuilder();
report.append("\n§8[§aEcoBridge§8] §7Performance Diagnostics\n");
long total = totalCalculations.sum();
long simd = simdCalculations.sum();
double ratio = total > 0 ? (100.0 * simd / total) : 0.0;
report.append(String.format(" §7SIMD: §f%d lanes §7| Ratio: §a%.1f%%\n", vectorLanes, ratio));
MemoryUsage heap = memoryBean.getHeapMemoryUsage();
long used = heap.getUsed() / 1048576;
long max = heap.getMax() / 1048576;
report.append(String.format(" §7Mem: §e%dMB/%dMB §7| Threads: §f%d\n",
used, max, threadBean.getThreadCount()));
if (youngGC != null) {
report.append(String.format(" §7GC(Young): §f%d runs §7| §e%dms\n",
youngGC.getCollectionCount(), youngGC.getCollectionTime()));
}
if (oldGC != null) {
report.append(String.format(" §7GC(Old):   §f%d runs §7| §c%dms\n",
oldGC.getCollectionCount(), oldGC.getCollectionTime()));
}
report.append(String.format(" §7TPS: §a%.1f §7| Players: §f%d\n", cachedTps[0], cachedPlayerCount));
if (pidController != null) {
report.append(String.format(" §7ContextPool: §f%d available\n", pidController.getContextPool().getAvailableCount()));
}
report.append(String.format(" §7DB IO: §fW:%,d R:%,d\n", dbWrites.sumThenReset(), dbReads.sumThenReset()));
if (!counters.isEmpty()) {
report.append(" §7Hotspots:\n");
counters.forEach((k, v) -> {
if (v.getCount() > 0) {
report.append(String.format("  - %s: §e%.3fms\n", k, v.getAverageMs()));
}
});
}
plugin.getLogger().info(report.toString());
totalCalculations.reset();
simdCalculations.reset();
scalarCalculations.reset();
} catch (Exception e) {
plugin.getLogger().warning("Error generating perf report: " + e.getMessage());
}
}
public record MonitorStats(double tps, long memoryUsedMB, int threadCount) {}
public static class PerformanceCounter {
private final AtomicLong totalNs = new AtomicLong(0);
private final AtomicLong count = new AtomicLong(0);
public void record(long nanoTime) {
totalNs.addAndGet(nanoTime);
count.incrementAndGet();
}
public double getAverageMs() {
long c = count.get();
return c > 0 ? (totalNs.get() / c / 1_000_000.0) : 0.0;
}
public long getCount() { return count.get(); }
}
public void recordCalculation(boolean usedSIMD) {
totalCalculations.increment();
if (usedSIMD) simdCalculations.increment(); else scalarCalculations.increment();
}
public void recordDbWrite() { dbWrites.increment(); }
public void recordDbRead() { dbReads.increment(); }
public void startTimer(String name) {
counters.computeIfAbsent(name, k -> new PerformanceCounter());
}
public void stopTimer(String name, long startNs) {
PerformanceCounter c = counters.get(name);
if (c != null) c.record(System.nanoTime() - startNs);
}
public MonitorStats getCurrentStats() {
MemoryUsage heap = memoryBean.getHeapMemoryUsage();
return new MonitorStats(
cachedTps[0],
heap.getUsed() / 1048576,
threadBean.getThreadCount()
);
}
public void shutdown() {
if (syncCacheTask != null && !syncCacheTask.isCancelled()) {
syncCacheTask.cancel();
}
scheduler.shutdown();
try {
if (!scheduler.awaitTermination(2, TimeUnit.SECONDS)) scheduler.shutdownNow();
} catch (InterruptedException e) { scheduler.shutdownNow(); }
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\PidController.java
==================================================

package top.ellan.ecobridge;
import jdk.incubator.vector.*;
import java.lang.foreign.*;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
public class PidController implements AutoCloseable {
private static final VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_PREFERRED;
private static final int V_LEN = SPECIES.length();
private static final int SEGMENT_BITS = 4;
private static final int SEGMENT_COUNT = 1 << SEGMENT_BITS;
private static final int SEGMENT_MASK = SEGMENT_COUNT - 1;
private static final int CAPACITY = 8192;
private static final int SLOT_MASK = 0xFFFF;
private static final ValueLayout.OfDouble D_LAYOUT = ValueLayout.JAVA_DOUBLE;
private static final ValueLayout.OfLong L_LAYOUT = ValueLayout.JAVA_LONG;
private static final long D_SIZE = 8L;
private double target;
private double deadband;
private double kp;
private double kpNegativeMultiplier;
private double ki;
private double kd;
private double base;
private double alpha;
private double beta;
private double tau;
private double integralMax;
private double integralMin;
private double lambdaMax;
private double lambdaMin;
private double dtMax;
private double dtMin;
private DoubleVector vTarget;
private DoubleVector vDeadband;
private DoubleVector vKp;
private DoubleVector vKpNeg;
private DoubleVector vKi;
private DoubleVector vKd;
private DoubleVector vBase;
private DoubleVector vAlpha;
private DoubleVector vBeta;
private DoubleVector vZero;
private DoubleVector vOne;
private DoubleVector vIMax;
private DoubleVector vIMin;
private DoubleVector vLMax;
private DoubleVector vLMin;
private DoubleVector vDtMax;
private DoubleVector vDtMin;
private DoubleVector vNegTauInv;
private final EcoBridge plugin;
private final Arena arena;
private final Segment[] segments;
private final ConcurrentHashMap<String, Integer> registry = new ConcurrentHashMap<>(4096);
private final ConcurrentHashMap<Integer, String> handleToId = new ConcurrentHashMap<>(4096);
private final AtomicBoolean closed = new AtomicBoolean(false);
private final DynamicCalcContextPool contextPool;
public PidController(EcoBridge plugin) {
this.plugin = plugin;
this.arena = Arena.ofAuto();
this.segments = new Segment[SEGMENT_COUNT];
for (int i = 0; i < SEGMENT_COUNT; i++) {
this.segments[i] = new Segment(arena);
}
int cores = Runtime.getRuntime().availableProcessors();
this.contextPool = new DynamicCalcContextPool(Math.max(4, cores), cores * 4);
loadConfig();
plugin.getLogger().info("[PID] Void-Object Controller Initialized. Zero-Boxing: Active | Padding: Active");
}
private void loadConfig() {
var cfg = plugin.getConfig();
this.target = cfg.getDouble("pid.target", 1000.0);
this.deadband = cfg.getDouble("pid.deadband", 20.0);
this.kp = cfg.getDouble("pid.kp", 0.00001);
this.kpNegativeMultiplier = cfg.getDouble("pid.kp-negative-multiplier", 0.6);
this.ki = cfg.getDouble("pid.ki", 0.000001);
this.kd = cfg.getDouble("pid.kd", 0.00005);
this.base = cfg.getDouble("pid.base", 0.002);
this.alpha = cfg.getDouble("pid.alpha", 0.05);
this.beta = cfg.getDouble("pid.beta", 0.95);
this.tau = cfg.getDouble("pid.tau", 0.00001929);
this.integralMax = cfg.getDouble("pid.integral-max", 30000.0);
this.integralMin = cfg.getDouble("pid.integral-min", -30000.0);
this.lambdaMax = cfg.getDouble("pid.lambda-max", 0.01);
this.lambdaMin = cfg.getDouble("pid.lambda-min", 0.0005);
this.dtMax = cfg.getDouble("pid.dt-max", 1.0);
this.dtMin = cfg.getDouble("pid.dt-min", 0.05);
initVectors();
}
private void initVectors() {
this.vTarget = DoubleVector.broadcast(SPECIES, target);
this.vDeadband = DoubleVector.broadcast(SPECIES, deadband);
this.vKp = DoubleVector.broadcast(SPECIES, kp);
this.vKpNeg = DoubleVector.broadcast(SPECIES, kp * kpNegativeMultiplier);
this.vKi = DoubleVector.broadcast(SPECIES, ki);
this.vKd = DoubleVector.broadcast(SPECIES, kd);
this.vBase = DoubleVector.broadcast(SPECIES, base);
this.vAlpha = DoubleVector.broadcast(SPECIES, alpha);
this.vBeta = DoubleVector.broadcast(SPECIES, beta);
this.vZero = DoubleVector.broadcast(SPECIES, 0.0);
this.vOne = DoubleVector.broadcast(SPECIES, 1.0);
this.vIMax = DoubleVector.broadcast(SPECIES, integralMax);
this.vIMin = DoubleVector.broadcast(SPECIES, integralMin);
this.vLMax = DoubleVector.broadcast(SPECIES, lambdaMax);
this.vLMin = DoubleVector.broadcast(SPECIES, lambdaMin);
this.vDtMax = DoubleVector.broadcast(SPECIES, dtMax);
this.vDtMin = DoubleVector.broadcast(SPECIES, dtMin);
this.vNegTauInv = DoubleVector.broadcast(SPECIES, -tau);
}
public void reloadConfig() {
loadConfig();
plugin.getLogger().info("[PID] Config reloaded.");
}
public int getHandle(String itemId) {
return registry.computeIfAbsent(itemId, id -> {
int hash = Math.abs(id.hashCode());
int segId = hash & SEGMENT_MASK;
Segment seg = segments[segId];
synchronized (seg.lock) {
int slot = seg.allocateSlot();
if (slot < 0) {
plugin.getLogger().warning("[PID] Segment " + segId + " overflow!");
return -1;
}
int handle = (segId << 16) | slot;
handleToId.put(handle, id);
return handle;
}
});
}
public double getLambdaByString(String itemId) {
Integer handle = registry.get(itemId);
if (handle == null) return base;
int segId = handle >>> 16;
int slot = handle & SLOT_MASK;
Segment seg = segments[segId];
long offset = (long) slot * D_SIZE;
synchronized (seg.lock) {
return seg.lambdas.get(D_LAYOUT, offset);
}
}
public void calculateBatch(int[] handles, double[] volumes, int count) {
if (closed.get() || count == 0) return;
CalcContext ctx = contextPool.acquire();
try {
ctx.reset();
for (int i = 0; i < count; i++) {
int h = handles[i];
if (h == -1) continue;
int segId = h >>> 16;
int slot = h & SLOT_MASK;
ctx.push(segId, slot, volumes[i]);
}
long now = System.currentTimeMillis();
for (int i = 0; i < SEGMENT_COUNT; i++) {
if (ctx.counts[i] > 0) {
processSegment(segments[i], ctx, i, now);
}
}
} catch (IllegalStateException e) {
plugin.getLogger().severe("PID Context Overflow: " + e.getMessage());
} catch (Exception e) {
plugin.getLogger().severe("PID Batch Error: " + e.getMessage());
} finally {
contextPool.release(ctx);
}
}
private void processSegment(Segment seg, CalcContext ctx, int segId, long now) {
int count = ctx.counts[segId];
int[] slots = ctx.segSlots[segId];
double[] localVols = ctx.segVols[segId];
double[] vBuf = ctx.vBufState;
synchronized (seg.lock) {
for (int i = 0; i < count; i++) {
long offset = (long) slots[i] * D_SIZE;
vBuf[i] = seg.integrals.get(D_LAYOUT, offset);
vBuf[i + count] = seg.errors.get(D_LAYOUT, offset);
vBuf[i + count * 2] = seg.lambdas.get(D_LAYOUT, offset);
vBuf[i + count * 3] = (now - seg.times.get(L_LAYOUT, offset)) * 0.001;
}
}
for (int i = 0; i < count; i += V_LEN) {
VectorMask<Double> m = SPECIES.indexInRange(i, count);
DoubleVector vI = DoubleVector.fromArray(SPECIES, vBuf, i, m);
DoubleVector vE = DoubleVector.fromArray(SPECIES, vBuf, i + count, m);
DoubleVector vL = DoubleVector.fromArray(SPECIES, vBuf, i + count * 2, m);
DoubleVector vDtRaw = DoubleVector.fromArray(SPECIES, vBuf, i + count * 3, m);
DoubleVector vVol = DoubleVector.fromArray(SPECIES, localVols, i, m);
DoubleVector vDt = vDtRaw.max(vDtMin).min(vDtMax);
DoubleVector vErrRaw = vVol.sub(vTarget);
VectorMask<Double> maskDead = vErrRaw.abs().compare(VectorOperators.LT, vDeadband);
DoubleVector vErr = vErrRaw.blend(vZero, maskDead);
DoubleVector vDecay = vDt.fma(vNegTauInv, vOne);
vI = vErr.fma(vDt, vI.mul(vDecay)).max(vIMin).min(vIMax);
VectorMask<Double> maskNeg = vErr.compare(VectorOperators.LT, vZero);
DoubleVector vKpUsed = vKp.blend(vKpNeg, maskNeg);
DoubleVector vP = vErr.mul(vKpUsed);
DoubleVector vD = vErr.sub(vE).div(vDt).mul(vKd);
DoubleVector vRes = vP.add(vI.mul(vKi)).add(vD).add(vBase);
vL = vL.fma(vBeta, vRes.mul(vAlpha)).max(vLMin).min(vLMax);
vI.intoArray(vBuf, i, m);
vErr.intoArray(vBuf, i + count, m);
vL.intoArray(vBuf, i + count * 2, m);
}
synchronized (seg.lock) {
for (int k = 0; k < count; k++) {
long offset = (long) slots[k] * D_SIZE;
seg.integrals.set(D_LAYOUT, offset, vBuf[k]);
seg.errors.set(D_LAYOUT, offset, vBuf[k + count]);
seg.lambdas.set(D_LAYOUT, offset, vBuf[k + count * 2]);
seg.times.set(L_LAYOUT, offset, now);
seg.markDirty(slots[k]);
}
}
}
private static class Segment {
final Object lock = new Object();
@SuppressWarnings("unused")
private long p1, p2, p3, p4, p5, p6, p7;
final MemorySegment integrals;
final MemorySegment errors;
final MemorySegment lambdas;
final MemorySegment times;
final BitSet allocationMap = new BitSet(CAPACITY);
private int[] dirtySlots;
private int dirtyCount;
Segment(Arena arena) {
integrals = arena.allocate(D_LAYOUT, CAPACITY);
errors = arena.allocate(D_LAYOUT, CAPACITY);
lambdas = arena.allocate(D_LAYOUT, CAPACITY);
times = arena.allocate(L_LAYOUT, CAPACITY);
this.dirtySlots = new int[64];
this.dirtyCount = 0;
warmup();
}
int allocateSlot() {
int slot = allocationMap.nextClearBit(0);
if (slot >= CAPACITY) return -1;
allocationMap.set(slot);
lambdas.setAtIndex(D_LAYOUT, slot, 0.002);
times.setAtIndex(L_LAYOUT, slot, System.currentTimeMillis());
return slot;
}
void warmup() {
for (int i = 0; i < CAPACITY; i += 512) {
integrals.setAtIndex(D_LAYOUT, i, 0);
}
}
void markDirty(int slot) {
if (dirtyCount > 0 && dirtySlots[dirtyCount - 1] == slot) {
return;
}
if (dirtyCount >= dirtySlots.length) {
dirtySlots = Arrays.copyOf(dirtySlots, dirtySlots.length + 32);
}
dirtySlots[dirtyCount++] = slot;
}
}
public static class DynamicCalcContextPool {
private final ConcurrentLinkedQueue<CalcContext> pool = new ConcurrentLinkedQueue<>();
private final AtomicInteger currentSize = new AtomicInteger(0);
@SuppressWarnings("unused")
private volatile int minSize;
private volatile int maxSize;
public DynamicCalcContextPool(int minSize, int maxSize) {
this.minSize = minSize;
this.maxSize = maxSize;
for (int i = 0; i < minSize; i++) {
pool.offer(new CalcContext());
currentSize.incrementAndGet();
}
}
public CalcContext acquire() {
CalcContext ctx = pool.poll();
if (ctx != null) {
currentSize.decrementAndGet();
} else {
ctx = new CalcContext();
}
ctx.reset();
return ctx;
}
public void release(CalcContext ctx) {
if (currentSize.get() < maxSize) {
pool.offer(ctx);
currentSize.incrementAndGet();
}
}
public int getAvailableCount() { return currentSize.get(); }
public int getMinSize() { return minSize; }
public void setMinSize(int newMin) { this.minSize = newMin;  }
public int getMaxSize() { return maxSize; }
public void setMaxSize(int newMax) { this.maxSize = newMax; }
}
private static class CalcContext {
static final int INITIAL_CAPACITY = 512;
static final int HARD_LIMIT = 1024 * 1024;
int[][] segSlots = new int[SEGMENT_COUNT][INITIAL_CAPACITY];
double[][] segVols = new double[SEGMENT_COUNT][INITIAL_CAPACITY];
final int[] counts = new int[SEGMENT_COUNT];
double[] vBufState;
CalcContext() {
this.vBufState = new double[INITIAL_CAPACITY * 4];
}
void reset() {
Arrays.fill(counts, 0);
}
void push(int segId, int slot, double vol) {
int idx = counts[segId];
if (idx >= segSlots[segId].length) {
grow(segId);
}
segSlots[segId][idx] = slot;
segVols[segId][idx] = vol;
counts[segId]++;
}
private void grow(int segId) {
int oldCap = segSlots[segId].length;
int newCap = Math.min(HARD_LIMIT, oldCap + (oldCap >> 1));
segSlots[segId] = Arrays.copyOf(segSlots[segId], newCap);
segVols[segId] = Arrays.copyOf(segVols[segId], newCap);
if (vBufState.length < newCap * 4) {
vBufState = new double[newCap * 4];
}
}
}
@Override
public void close() {
if (closed.compareAndSet(false, true)) {
if (arena.scope().isAlive()) arena.close();
}
}
public int getCacheSize() {
return registry.size();
}
public int getDirtyQueueSize() {
int total = 0;
for (Segment seg : segments) {
total += seg.dirtyCount;
}
return total;
}
public void flushBuffer(boolean sync) {
if (closed.get()) return;
List<DatabaseManager.PidDbSnapshot> batch = new ArrayList<>();
for (int segId = 0; segId < SEGMENT_COUNT; segId++) {
Segment seg = segments[segId];
int[] slotsToFlush;
int countToFlush;
synchronized (seg.lock) {
if (seg.dirtyCount == 0) continue;
slotsToFlush = seg.dirtySlots;
countToFlush = seg.dirtyCount;
seg.dirtySlots = new int[64];
seg.dirtyCount = 0;
}
for (int k = 0; k < countToFlush; k++) {
int slot = slotsToFlush[k];
String id = handleToId.get((segId << 16) | slot);
if (id != null) {
long offset = (long) slot * D_SIZE;
batch.add(new DatabaseManager.PidDbSnapshot(
id, seg.integrals.get(D_LAYOUT, offset), seg.errors.get(D_LAYOUT, offset),
seg.lambdas.get(D_LAYOUT, offset), seg.times.get(L_LAYOUT, offset)
));
}
}
}
if (batch.isEmpty()) return;
if (sync) plugin.getDatabaseManager().saveBatch(batch);
else Thread.ofVirtual().name("eb-db-flush").start(() -> plugin.getDatabaseManager().saveBatch(batch));
}
public PidStateDto inspectState(String itemId) {
Integer handle = registry.get(itemId);
if (handle == null) return null;
int segId = handle >>> 16;
int slot = handle & SLOT_MASK;
Segment seg = segments[segId];
long offset = (long) slot * D_SIZE;
synchronized (seg.lock) {
return new PidStateDto(
seg.integrals.get(D_LAYOUT, offset),
seg.errors.get(D_LAYOUT, offset),
seg.lambdas.get(D_LAYOUT, offset),
seg.times.get(L_LAYOUT, offset)
);
}
}
public record PidStateDto(double integral, double lastError, double lastLambda, long updateTime) {}
public void loadAllStates() {
if (closed.get()) return;
plugin.getDatabaseManager().loadStates(snapshot -> {
int handle = getHandle(snapshot.itemId());
if (handle < 0) return;
int segId = handle >>> 16;
int slot = handle & SLOT_MASK;
Segment seg = segments[segId];
long offset = (long) slot * D_SIZE;
synchronized (seg.lock) {
seg.integrals.set(D_LAYOUT, offset, snapshot.integral());
seg.errors.set(D_LAYOUT, offset, snapshot.lastError());
seg.lambdas.set(D_LAYOUT, offset, snapshot.lastLambda());
seg.times.set(L_LAYOUT, offset, snapshot.updateTime());
seg.markDirty(slot);
}
});
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\TradeMetadata.java
==================================================

package top.ellan.ecobridge;
public record TradeMetadata(
String technicalId,
String displayName,
String shopName
) {}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\WebManager.java
==================================================

package top.ellan.ecobridge;
import java.lang.invoke.MethodHandles;
import java.lang.invoke.VarHandle;
import java.net.URI;
import java.net.http.HttpClient;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.time.Duration;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.LongAdder;
import java.util.concurrent.atomic.DoubleAccumulator;
import java.util.concurrent.atomic.LongAccumulator;
import java.util.concurrent.locks.LockSupport;
public class WebManager {
private final EcoBridge plugin;
private volatile boolean running = true;
private final String nodeApiUrl;
private static final int MAX_BATCH_SIZE = 64;
private static final long FLUSH_INTERVAL_MS = 50;
private final int capacity;
private final int indexMask;
private final long[] tsBuffer;
private final double[] infBuffer;
private final double[] tpsBuffer;
private final int[] memBuffer;
private final int[] threadBuffer;
private static final VarHandle WRITE_CURSOR;
static {
try {
MethodHandles.Lookup l = MethodHandles.lookup();
WRITE_CURSOR = l.findVarHandle(WebManager.class, "writeSequence", long.class);
} catch (ReflectiveOperationException e) {
throw new ExceptionInInitializerError(e);
}
}
@SuppressWarnings("unused")
private long p1, p2, p3, p4, p5, p6, p7;
@SuppressWarnings("unused")
private volatile long writeSequence;
@SuppressWarnings("unused")
private long p8, p9, p10, p11, p12, p13, p14, p15;
private volatile long readSequence = 0L;
private final LockFreeAggregator aggregator;
private final ExecutorService httpClientExecutor;
private final HttpClient httpClient;
private Thread senderThread;
private final LongAdder errorCounter = new LongAdder();
public WebManager(EcoBridge plugin) {
this.plugin = plugin;
this.nodeApiUrl = plugin.getConfig().getString("web.node-api-url", "http:
this.httpClientExecutor = Executors.newVirtualThreadPerTaskExecutor();
this.httpClient = HttpClient.newBuilder()
.version(HttpClient.Version.HTTP_2)
.executor(httpClientExecutor)
.connectTimeout(Duration.ofSeconds(5))
.build();
int configCap = plugin.getConfig().getInt("web.history-capacity", 1024);
this.capacity = Integer.highestOneBit(configCap) == configCap ? configCap : Integer.highestOneBit(configCap) << 1;
this.indexMask = capacity - 1;
this.tsBuffer = new long[capacity];
this.infBuffer = new double[capacity];
this.tpsBuffer = new double[capacity];
this.memBuffer = new int[capacity];
this.threadBuffer = new int[capacity];
this.aggregator = new LockFreeAggregator(plugin);
startBatchSender();
plugin.getLogger().info("[Web] Production Build Initialized | Buffer: " + capacity + " | VThread Executor Active");
}
public void pushMetrics(double inflation, PerformanceMonitor.MonitorStats stats) {
if (!running) return;
long seq = (long) WRITE_CURSOR.getAndAddRelease(this, 1L);
long lag = seq - readSequence;
if (lag >= capacity) {
readSequence = seq - capacity + 1;
}
int idx = (int) (seq & indexMask);
tsBuffer[idx] = System.currentTimeMillis();
infBuffer[idx] = inflation;
tpsBuffer[idx] = stats.tps();
memBuffer[idx] = (int) stats.memoryUsedMB();
threadBuffer[idx] = stats.threadCount();
VarHandle.releaseFence();
aggregator.observe(stats.tps(), stats.memoryUsedMB());
}
private void startBatchSender() {
this.senderThread = Thread.ofVirtual()
.name("web-batch-sender")
.start(this::batchSendLoop);
}
private void batchSendLoop() {
long lastFlushTime = System.currentTimeMillis();
while (running) {
long writeSeq = (long) WRITE_CURSOR.getAcquire(this);
long available = writeSeq - readSequence;
if (available <= 0) {
LockSupport.parkNanos(TimeUnit.MICROSECONDS.toNanos(200));
continue;
}
int batchSize = (int) Math.min(available, MAX_BATCH_SIZE);
String payload = buildBatchJson(readSequence, batchSize);
try {
HttpRequest request = HttpRequest.newBuilder()
.uri(URI.create(nodeApiUrl))
.header("Content-Type", "application/json")
.POST(HttpRequest.BodyPublishers.ofString(payload))
.timeout(Duration.ofSeconds(2))
.build();
HttpResponse<Void> response = httpClient.send(request, HttpResponse.BodyHandlers.discarding());
if (response.statusCode() == 200) {
readSequence += batchSize;
} else {
handleError("Status " + response.statusCode());
}
} catch (Exception e) {
handleError(e.getMessage());
}
long now = System.currentTimeMillis();
if (now - lastFlushTime < FLUSH_INTERVAL_MS) {
if (available <= MAX_BATCH_SIZE * 2) {
LockSupport.parkNanos(TimeUnit.MICROSECONDS.toNanos(200));
}
} else {
lastFlushTime = now;
}
}
}
private String buildBatchJson(long startSeq, int size) {
StringBuilder sb = new StringBuilder(32 + size * 80);
sb.append("{\"batch\":[");
for (int i = 0; i < size; i++) {
int idx = (int) ((startSeq + i) & indexMask);
sb.append('{')
.append("\"ts\":").append(tsBuffer[idx]).append(',')
.append("\"inf\":").append(infBuffer[idx]).append(',')
.append("\"tps\":").append(tpsBuffer[idx]).append(',')
.append("\"mem\":").append(memBuffer[idx]).append(',')
.append("\"threads\":").append(threadBuffer[idx])
.append('}');
if (i < size - 1) sb.append(',');
}
sb.append("]}");
return sb.toString();
}
private void handleError(String reason) {
errorCounter.increment();
long count = errorCounter.sum();
if ((count & 0xFF) == 0) {
plugin.getLogger().warning("[Web] Push failed x256. Reason: " + reason);
}
}
public void shutdown() {
running = false;
if (senderThread != null) {
LockSupport.unpark(senderThread);
senderThread.interrupt();
}
if (httpClientExecutor != null) {
httpClientExecutor.shutdown();
try {
if (!httpClientExecutor.awaitTermination(1, TimeUnit.SECONDS)) {
httpClientExecutor.shutdownNow();
}
} catch (InterruptedException e) {
httpClientExecutor.shutdownNow();
}
}
aggregator.reset();
plugin.getLogger().info("[Web] Production Build Shutdown Gracefully");
}
public static class LockFreeAggregator {
private final DoubleAccumulator minTps = new DoubleAccumulator(Math::min, 20.0);
private final DoubleAccumulator maxTps = new DoubleAccumulator(Math::max, 0.0);
private final LongAccumulator maxMemory = new LongAccumulator(Math::max, 0L);
private static final VarHandle LAST_RESET;
static {
try {
MethodHandles.Lookup l = MethodHandles.lookup();
LAST_RESET = l.findVarHandle(LockFreeAggregator.class, "lastResetTime", long.class);
} catch (ReflectiveOperationException e) {
throw new ExceptionInInitializerError(e);
}
}
@SuppressWarnings("unused")
private volatile long lastResetTime = System.currentTimeMillis();
private final long windowSizeMs;
private final EcoBridge plugin;
public LockFreeAggregator(EcoBridge plugin) {
this.plugin = plugin;
this.windowSizeMs = TimeUnit.MINUTES.toMillis(5);
}
public void observe(double tps, long memory) {
long now = System.currentTimeMillis();
long lastReset = (long) LAST_RESET.getOpaque(this);
if (now - lastReset > windowSizeMs) {
if (LAST_RESET.compareAndSet(this, lastReset, now)) {
resetStats();
}
}
minTps.accumulate(tps);
maxTps.accumulate(tps);
maxMemory.accumulate(memory);
}
public double getMinTps() { return minTps.get(); }
public double getMaxTps() { return maxTps.get(); }
public long getMaxMemory() { return maxMemory.get(); }
private void resetStats() {
minTps.reset();
maxTps.reset();
maxMemory.reset();
plugin.getLogger().fine("[Web] Aggregator reset");
}
public void reset() {
LAST_RESET.setRelease(this, System.currentTimeMillis());
resetStats();
}
}
}
