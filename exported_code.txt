
==================================================
FILE: EcoBridge_Project\build.gradle.kts
==================================================

plugins {
`java-library`
// [修正] 使用新的 Plugin ID 和最新版本
id("io.papermc.paperweight.userdev") version "2.0.0-beta.19"
// 快速启动服务端测试插件
id("xyz.jpenilla.run-paper") version "2.3.0"
// Shadow 插件
id("com.gradleup.shadow") version "9.3.1"
}
group = "top.ellan"
version = "1.0-SNAPSHOT"
java {
// 保持使用 Java 25 (开启 Vector API 必须)
toolchain.languageVersion.set(JavaLanguageVersion.of(25))
}
repositories {
mavenCentral()
maven("https://repo.papermc.io/repository/maven-public/")
maven("https://repo.extendedclip.com/content/repositories/placeholderapi/")
maven("https://repo.nightexpressdev.com/releases")
maven("https://jitpack.io")
maven("https://repo.lanink.cn/repository/maven-public/")
flatDir { dirs("libs") }
}
dependencies {
// 1. 核心开发环境
paperweight.paperDevBundle("1.21.11-R0.1-SNAPSHOT")
// 2. 外部插件依赖
compileOnly("me.clip:placeholderapi:2.11.6")
compileOnly("su.nightexpress.coinsengine:CoinsEngine:2.6.0")
compileOnly("su.nightexpress.nightcore:main:2.13.0")
compileOnly("cn.superiormc.ultimateshop:plugin:4.2.3")
// 本地 libs
compileOnly(fileTree(mapOf("dir" to "libs", "include" to listOf("*.jar"))))
// 3. 知识提取/数据处理库
implementation(platform("com.fasterxml.jackson:jackson-bom:2.17.0"))
implementation("com.fasterxml.jackson.core:jackson-databind")
implementation("com.fasterxml.jackson.core:jackson-core")
implementation("com.fasterxml.jackson.core:jackson-annotations")
implementation("redis.clients:jedis:5.2.0")
implementation("com.zaxxer:HikariCP:7.0.2")
implementation("com.github.ben-manes.caffeine:caffeine:3.2.3")
}
tasks {
compileJava {
options.encoding = "UTF-8"
// [必要修改] 必须设置为 25 以匹配 toolchain 并支持 Vector API
options.release.set(25)
// [必要修改] 开启预览特性和 Vector 孵化模块
options.compilerArgs.addAll(listOf(
"--enable-preview",
"--add-modules=jdk.incubator.vector"
))
}
processResources {
val props = mapOf("version" to version)
inputs.properties(props)
filteringCharset = "UTF-8"
filesMatching("plugin.yml") {
expand(props)
}
}
// ShadowJar 配置
named<com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar>("shadowJar") {
archiveClassifier.set("")
val prefix = "top.ellan.ecobridge.libs"
relocate("com.fasterxml.jackson", "$prefix.jackson")
relocate("com.zaxxer.hikari", "$prefix.hikari")
relocate("redis.clients", "$prefix.jedis")
relocate("org.apache.commons.pool2", "$prefix.commons.pool2")
relocate("org.json", "$prefix.json")
relocate("com.github.benmanes.caffeine", "$prefix.caffeine")
exclude("META-INF/*.SF", "META-INF/*.DSA", "META-INF/*.RSA")
exclude("META-INF/maven/**")
minimize {
exclude(dependency("com.zaxxer:HikariCP:.*"))
}
}
build {
dependsOn("shadowJar")
}
}

==================================================
FILE: EcoBridge_Project\settings.gradle.kts
==================================================

pluginManagement {
repositories {
gradlePluginPortal()
mavenCentral()
maven("https://repo.papermc.io/repository/maven-public/")
}
}
rootProject.name = "EcoBridge"

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\DatabaseManager.java
==================================================

package top.ellan.ecobridge;
import com.zaxxer.hikari.HikariConfig;
import com.zaxxer.hikari.HikariDataSource;
import java.sql.*;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.logging.Level;
public class DatabaseManager {
public record PidDbSnapshot(String itemId, double integral, double lastError,
double lastLambda, long updateTime) {}
private final EcoBridge plugin;
private HikariDataSource dataSource;
private final BlockingQueue<PidDbSnapshot> pendingWrites = new LinkedBlockingQueue<>(10000);
private final ScheduledExecutorService batchScheduler = Executors.newSingleThreadScheduledExecutor(
Thread.ofVirtual().factory()
);
private final AtomicInteger optimalBatchSize = new AtomicInteger(500);
private volatile boolean initialized = false;
public DatabaseManager(EcoBridge plugin) {
this.plugin = plugin;
}
public void initPool() {
Thread.ofVirtual().start(() -> {
try {
HikariConfig config = buildConfig();
this.dataSource = new HikariDataSource(config);
warmupPool();
createTable();
startBatchWriter();
initialized = true;
plugin.getLogger().info("[DB] HikariCP initialized: " +
config.getMaximumPoolSize() + " connections, VirtualThread enabled");
plugin.getPidController().loadAllStates();
} catch (Exception e) {
plugin.getLogger().severe("[DB] Init failed: " + e.getMessage());
e.printStackTrace();
}
});
}
private HikariConfig buildConfig() {
HikariConfig config = new HikariConfig();
String url = plugin.getConfig().getString("database.url",
"jdbc:mariadb:
String user = plugin.getConfig().getString("database.user", "root");
String pass = plugin.getConfig().getString("database.password", "password");
config.setJdbcUrl(url);
config.setUsername(user);
config.setPassword(pass);
config.addDataSourceProperty("cachePrepStmts", "true");
config.addDataSourceProperty("prepStmtCacheSize", "500");
config.addDataSourceProperty("prepStmtCacheSqlLimit", "4096");
config.addDataSourceProperty("useServerPrepStmts", "true");
config.addDataSourceProperty("useLocalSessionState", "true");
config.addDataSourceProperty("rewriteBatchedStatements", "true");
config.addDataSourceProperty("cacheResultSetMetadata", "true");
config.addDataSourceProperty("cacheServerConfiguration", "true");
config.addDataSourceProperty("elideSetAutoCommits", "true");
config.addDataSourceProperty("maintainTimeStats", "false");
config.addDataSourceProperty("useUnbufferedInput", "false");
config.setMaximumPoolSize(16);
config.setMinimumIdle(4);
config.setIdleTimeout(300000);
config.setConnectionTimeout(10000);
config.setMaxLifetime(1800000);
config.setKeepaliveTime(60000);
config.setLeakDetectionThreshold(30000);
config.setPoolName("EcoBridge-Hikari");
config.setThreadFactory(Thread.ofVirtual().factory());
return config;
}
private void warmupPool() {
try (Connection conn = dataSource.getConnection()) {
try (Statement stmt = conn.createStatement()) {
stmt.execute("SELECT 1");
}
plugin.getLogger().info("[DB] Connection pool warmed up");
} catch (SQLException e) {
plugin.getLogger().warning("[DB] Warmup failed: " + e.getMessage());
}
}
private void createTable() throws SQLException {
try (Connection conn = dataSource.getConnection();
Statement stmt = conn.createStatement()) {
stmt.execute("""
CREATE TABLE IF NOT EXISTS eb_pid_states (
item_id VARCHAR(64) PRIMARY KEY,
integral DOUBLE NOT NULL DEFAULT 0,
last_error DOUBLE NOT NULL DEFAULT 0,
last_lambda DOUBLE NOT NULL DEFAULT 0.002,
update_time BIGINT NOT NULL DEFAULT 0,
INDEX idx_update_time (update_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
ROW_FORMAT=DYNAMIC
""");
plugin.getLogger().info("[DB] Table 'eb_pid_states' ready");
}
}
private void startBatchWriter() {
batchScheduler.scheduleAtFixedRate(() -> {
try {
flushPendingWrites();
} catch (Exception e) {
plugin.getLogger().log(Level.WARNING, "[DB] Batch write error", e);
}
}, 500, 500, TimeUnit.MILLISECONDS);
}
public void saveBatch(List<PidDbSnapshot> snapshots) {
if (!initialized || snapshots.isEmpty()) return;
if (snapshots.size() <= 100) {
pendingWrites.addAll(snapshots);
return;
}
Thread.ofVirtual().start(() -> executeBatchWrite(snapshots));
}
private void flushPendingWrites() {
if (pendingWrites.isEmpty()) return;
List<PidDbSnapshot> batch = new ArrayList<>(optimalBatchSize.get());
pendingWrites.drainTo(batch, optimalBatchSize.get());
if (!batch.isEmpty()) {
executeBatchWrite(batch);
}
}
private void executeBatchWrite(List<PidDbSnapshot> snapshots) {
if (dataSource == null || dataSource.isClosed()) return;
String sql = """
INSERT INTO eb_pid_states (item_id, integral, last_error, last_lambda, update_time)
VALUES (?, ?, ?, ?, ?)
ON DUPLICATE KEY UPDATE
integral = VALUES(integral),
last_error = VALUES(last_error),
last_lambda = VALUES(last_lambda),
update_time = VALUES(update_time)
""";
long startNs = System.nanoTime();
try (Connection conn = dataSource.getConnection()) {
boolean originalAutoCommit = conn.getAutoCommit();
conn.setAutoCommit(false);
try (PreparedStatement ps = conn.prepareStatement(sql)) {
for (PidDbSnapshot record : snapshots) {
ps.setString(1, record.itemId());
ps.setDouble(2, record.integral());
ps.setDouble(3, record.lastError());
ps.setDouble(4, record.lastLambda());
ps.setLong(5, record.updateTime());
ps.addBatch();
}
ps.executeBatch();
conn.commit();
long elapsedMs = (System.nanoTime() - startNs) / 1_000_000;
adjustBatchSize(snapshots.size(), elapsedMs);
if (plugin.getConfig().getBoolean("debug-db", false)) {
plugin.getLogger().info(String.format(
"[DB] Saved %d items in %dms (%.1f items/ms)",
snapshots.size(), elapsedMs, snapshots.size() / (double) Math.max(1, elapsedMs)
));
}
} catch (SQLException e) {
conn.rollback();
throw e;
} finally {
conn.setAutoCommit(originalAutoCommit);
}
} catch (SQLException e) {
plugin.getLogger().log(Level.WARNING,
"[DB] Batch save failed for " + snapshots.size() + " items", e);
}
}
private void adjustBatchSize(int currentSize, long elapsedMs) {
if (elapsedMs < 50) {
optimalBatchSize.updateAndGet(old -> Math.min(2000, (int) (old * 1.2)));
} else if (elapsedMs > 150) {
optimalBatchSize.updateAndGet(old -> Math.max(100, (int) (old * 0.8)));
}
}
public void loadStates(java.util.function.Consumer<PidDbSnapshot> consumer) {
if (dataSource == null || dataSource.isClosed()) return;
Thread.ofVirtual().start(() -> {
try (Connection conn = dataSource.getConnection();
Statement stmt = conn.createStatement()) {
stmt.setFetchSize(1000);
try (ResultSet rs = stmt.executeQuery("SELECT * FROM eb_pid_states")) {
int count = 0;
while (rs.next()) {
consumer.accept(new PidDbSnapshot(
rs.getString("item_id"),
rs.getDouble("integral"),
rs.getDouble("last_error"),
rs.getDouble("last_lambda"),
rs.getLong("update_time")
));
count++;
}
plugin.getLogger().info("[DB] Loaded " + count + " PID states from database");
}
} catch (SQLException e) {
plugin.getLogger().severe("[DB] Failed to load states: " + e.getMessage());
e.printStackTrace();
}
});
}
public void closePool() {
flushPendingWrites();
batchScheduler.shutdown();
try {
if (!batchScheduler.awaitTermination(5, TimeUnit.SECONDS)) {
batchScheduler.shutdownNow();
}
} catch (InterruptedException e) {
batchScheduler.shutdownNow();
}
if (dataSource != null && !dataSource.isClosed()) {
dataSource.close();
plugin.getLogger().info("[DB] Connection pool closed");
}
}
public HikariDataSource getDataSource() {
return dataSource;
}
public boolean isInitialized() {
return initialized;
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\EcoBridge.java
==================================================

package top.ellan.ecobridge;
import org.bukkit.Bukkit;
import org.bukkit.plugin.java.JavaPlugin;
import org.bukkit.scheduler.BukkitRunnable;
public class EcoBridge extends JavaPlugin {
private static EcoBridge instance;
private DatabaseManager databaseManager;
private PidController pidController;
private MarketManager marketManager;
private IntegrationManager integrationManager;
private PerformanceMonitor performanceMonitor;
private volatile boolean fullyInitialized = false;
@Override
public void onEnable() {
instance = this;
long startTime = System.currentTimeMillis();
getLogger().info("═══════════════════════════════════════════════");
getLogger().info("  EcoBridge - Java 25 Extreme Performance");
getLogger().info("  SIMD + FFM + VirtualThreads + SoA Layout");
getLogger().info("═══════════════════════════════════════════════");
try {
saveDefaultConfig();
initializeComponents();
databaseManager.initPool();
registerPlaceholderAPI();
registerCommands();
startSchedulers();
if (getConfig().getBoolean("monitoring.enabled", true)) {
performanceMonitor = new PerformanceMonitor(this);
getLogger().info("Performance monitoring enabled");
}
warmupCriticalPaths();
fullyInitialized = true;
long elapsedMs = System.currentTimeMillis() - startTime;
getLogger().info("═══════════════════════════════════════════════");
getLogger().info("  ✓ EcoBridge loaded successfully in " + elapsedMs + "ms");
getLogger().info("═══════════════════════════════════════════════");
} catch (Exception e) {
getLogger().severe("═══════════════════════════════════════════════");
getLogger().severe("  ✗ FATAL: Failed to initialize EcoBridge");
getLogger().severe("═══════════════════════════════════════════════");
e.printStackTrace();
emergencyShutdown();
Bukkit.getPluginManager().disablePlugin(this);
}
}
@Override
public void onDisable() {
getLogger().info("═══════════════════════════════════════════════");
getLogger().info("  Gracefully shutting down EcoBridge...");
getLogger().info("═══════════════════════════════════════════════");
fullyInitialized = false;
try {
if (performanceMonitor != null) {
getLogger().info("[1/6] Stopping performance monitor...");
performanceMonitor.shutdown();
}
if (pidController != null) {
getLogger().info("[2/6] Flushing PID buffer...");
int pendingWrites = pidController.getDirtyQueueSize();
if (pendingWrites > 0) {
getLogger().info("  → " + pendingWrites + " pending writes");
}
pidController.flushBuffer(true);
waitForDatabaseFlush(5000);
getLogger().info("  → Closing FFM Arena...");
pidController.close();
}
if (marketManager != null) {
getLogger().info("[3/6] Shutting down market manager...");
marketManager.shutdown();
}
if (integrationManager != null) {
getLogger().info("[4/6] Closing integration manager...");
}
if (databaseManager != null) {
getLogger().info("[5/6] Closing database pool...");
databaseManager.closePool();
}
getLogger().info("[6/6] Cleaning up references...");
instance = null;
getLogger().info("═══════════════════════════════════════════════");
getLogger().info("  ✓ EcoBridge shutdown complete");
getLogger().info("═══════════════════════════════════════════════");
} catch (Exception e) {
getLogger().severe("Error during shutdown: " + e.getMessage());
e.printStackTrace();
}
}
private void initializeComponents() {
getLogger().info("Initializing core components...");
this.databaseManager = new DatabaseManager(this);
getLogger().info("  ✓ DatabaseManager");
this.pidController = new PidController(this);
getLogger().info("  ✓ PidController (SoA + SIMD)");
this.marketManager = new MarketManager(this);
getLogger().info("  ✓ MarketManager (VirtualThreads)");
this.integrationManager = new IntegrationManager(this);
getLogger().info("  ✓ IntegrationManager");
}
private void registerPlaceholderAPI() {
if (Bukkit.getPluginManager().getPlugin("PlaceholderAPI") != null) {
new EcoBridgeExpansion(this).register();
getLogger().info("  ✓ PlaceholderAPI integration");
} else {
getLogger().warning("  ⚠ PlaceholderAPI not found (variables disabled)");
}
}
private void registerCommands() {
if (getCommand("ecobridge") != null) {
EcoBridgeCommand commandHandler = new EcoBridgeCommand(this);
getCommand("ecobridge").setExecutor(commandHandler);
getCommand("ecobridge").setTabCompleter(commandHandler);
getLogger().info("  ✓ Commands registered (/eb, /ecobridge)");
} else {
getLogger().severe("  ✗ Failed to register command! Check plugin.yml");
}
}
private void startSchedulers() {
getLogger().info("Starting schedulers...");
long mainInterval = getConfig().getLong("schedulers.main-loop.period", 1200L);
long mainDelay = getConfig().getLong("schedulers.main-loop.initial-delay", 1200L);
new BukkitRunnable() {
@Override
public void run() {
if (!fullyInitialized) return;
try {
integrationManager.collectDataAndCalculate();
pidController.flushBuffer(false);
marketManager.updateActivityFactor();
} catch (Exception e) {
getLogger().warning("[Scheduler] Main loop error: " + e.getMessage());
}
}
}.runTaskTimer(this, mainDelay, mainInterval);
getLogger().info("  ✓ Main loop: every " + (mainInterval / 20) + "s");
long economyInterval = getConfig().getLong("schedulers.economy-update.period", 36000L);
long economyDelay = getConfig().getLong("schedulers.economy-update.initial-delay", 100L);
new BukkitRunnable() {
@Override
public void run() {
if (!fullyInitialized) return;
try {
marketManager.updateEconomyMetrics();
} catch (Exception e) {
getLogger().warning("[Scheduler] Economy update error: " + e.getMessage());
}
}
}.runTaskTimerAsynchronously(this, economyDelay, economyInterval);
getLogger().info("  ✓ Economy update: every " + (economyInterval / 20 / 60) + "min");
long marketInterval = getConfig().getLong("schedulers.market-flux-update.period", 6000L);
long marketDelay = getConfig().getLong("schedulers.market-flux-update.initial-delay", 20L);
new BukkitRunnable() {
@Override
public void run() {
if (!fullyInitialized) return;
try {
marketManager.updateMarketFlux();
marketManager.updateHolidayCache();
} catch (Exception e) {
getLogger().warning("[Scheduler] Market flux error: " + e.getMessage());
}
}
}.runTaskTimerAsynchronously(this, marketDelay, marketInterval);
getLogger().info("  ✓ Market flux: every " + (marketInterval / 20 / 60) + "min");
}
private void warmupCriticalPaths() {
if (!getConfig().getBoolean("performance.memory-warmup", true)) return;
getLogger().info("Warming up critical paths...");
Thread.ofVirtual().start(() -> {
try {
int retries = 0;
while (!databaseManager.isInitialized() && retries++ < 50) {
Thread.sleep(100);
}
if (databaseManager.isInitialized()) {
integrationManager.syncShops();
getLogger().info("  ✓ Shop data synced");
marketManager.updateMarketFlux();
marketManager.updateHolidayCache();
getLogger().info("  ✓ Market data initialized");
getLogger().info("  ✓ Warmup complete");
} else {
getLogger().warning("  ⚠ Database not ready, skipping warmup");
}
} catch (Exception e) {
getLogger().warning("Warmup error: " + e.getMessage());
}
});
}
private void waitForDatabaseFlush(long timeoutMs) {
long startTime = System.currentTimeMillis();
while (System.currentTimeMillis() - startTime < timeoutMs) {
int pending = pidController.getDirtyQueueSize();
if (pending == 0) {
getLogger().info("  ✓ All data flushed to database");
return;
}
try {
Thread.sleep(100);
} catch (InterruptedException e) {
break;
}
}
getLogger().warning("  ⚠ Database flush timeout, some data may be lost");
}
private void emergencyShutdown() {
try {
if (pidController != null) pidController.close();
if (marketManager != null) marketManager.shutdown();
if (databaseManager != null) databaseManager.closePool();
if (performanceMonitor != null) performanceMonitor.shutdown();
} catch (Exception e) {
}
}
public static EcoBridge getInstance() {
return instance;
}
public DatabaseManager getDatabaseManager() {
return databaseManager;
}
public PidController getPidController() {
return pidController;
}
public MarketManager getMarketManager() {
return marketManager;
}
public IntegrationManager getIntegrationManager() {
return integrationManager;
}
public PerformanceMonitor getPerformanceMonitor() {
return performanceMonitor;
}
public boolean isFullyInitialized() {
return fullyInitialized;
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\EcoBridgeCommand.java
==================================================

package top.ellan.ecobridge;
import net.kyori.adventure.text.minimessage.MiniMessage;
import org.bukkit.Bukkit;
import org.bukkit.command.Command;
import org.bukkit.command.CommandExecutor;
import org.bukkit.command.CommandSender;
import org.bukkit.command.TabCompleter;
import org.bukkit.entity.Player;
import org.jetbrains.annotations.NotNull;
import org.jetbrains.annotations.Nullable;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.stream.Collectors;
public class EcoBridgeCommand implements CommandExecutor, TabCompleter {
private final EcoBridge plugin;
private final MiniMessage mm = MiniMessage.miniMessage();
public EcoBridgeCommand(EcoBridge plugin) {
this.plugin = plugin;
}
private void msg(CommandSender sender, String message) {
sender.sendMessage(mm.deserialize(message));
}
@Override
public boolean onCommand(@NotNull CommandSender sender, @NotNull Command command,
@NotNull String label, @NotNull String[] args) {
if (!sender.hasPermission("ecobridge.admin")) {
msg(sender, "<red>❌ 你没有权限执行此操作。");
return true;
}
if (args.length == 0 || args[0].equalsIgnoreCase("help")) {
sendHelp(sender);
return true;
}
String sub = args[0].toLowerCase();
switch (sub) {
case "reload" -> handleReload(sender);
case "check" -> handleCheck(sender, args);
case "perf" -> handlePerf(sender);
case "save" -> handleSave(sender);
case "inspect" -> handleInspect(sender, args);
case "simd" -> handleSIMD(sender);
case "health" -> handleHealth(sender);
case "benchmark" -> handleBenchmark(sender, args);
default -> sendHelp(sender);
}
return true;
}
private void sendHelp(CommandSender sender) {
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:gold:yellow><bold>EcoBridge</gradient> <dark_gray>» <gray>v" +
plugin.getPluginMeta().getVersion());
msg(sender, "");
msg(sender, " <yellow>基础维护:");
msg(sender, "  <gold>/eb reload <dark_gray>• <gray>热重载配置、商店与市场缓存 ");
msg(sender, "  <gold>/eb check [玩家] <dark_gray>• <gray>分析指定玩家的经济因子");
msg(sender, "  <gold>/eb inspect <ID> <dark_gray>• <gray>实时审查物品 PID 运行数据");
msg(sender, "  <gold>/eb save <dark_gray>• <gray>强制刷写脏数据至数据库");
msg(sender, "");
msg(sender, " <yellow>高级诊断:");
msg(sender, "  <gold>/eb perf <dark_gray>• <gray>查看内存、TPS 及缓存统计");
msg(sender, "  <gold>/eb simd <dark_gray>• <gray>CPU 向量化指令集兼容性诊断");
msg(sender, "  <gold>/eb health <dark_gray>• <gray>系统模块健康度自动化检查");
msg(sender, "  <gold>/eb benchmark <dark_gray>• <gray>执行非线性压力基准测试");
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleReload(CommandSender sender) {
msg(sender, "<yellow>⟳ 正在异步重载全系统模块...");
Bukkit.getScheduler().runTaskAsynchronously(plugin, () -> {
long start = System.currentTimeMillis();
try {
plugin.reloadConfig();
plugin.getIntegrationManager().syncShops();
plugin.getMarketManager().updateHolidayCache();
plugin.getMarketManager().updateEconomyMetrics();
plugin.getMarketManager().updateMarketFlux();
msg(sender, "<green>✓ 重载成功! 耗时: <white>" + (System.currentTimeMillis() - start) + "ms");
} catch (Exception e) {
msg(sender, "<red>✗ 重载失败: " + e.getMessage());
}
});
}
private void handlePerf(CommandSender sender) {
Runtime rt = Runtime.getRuntime();
double usedMem = (rt.totalMemory() - rt.freeMemory()) / 1048576.0;
double maxMem = rt.maxMemory() / 1048576.0;
double tps = Bukkit.getTPS()[0];
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:gold:yellow>性能实时监控</gradient>");
msg(sender, " <gray>控制器缓存: <aqua>" + plugin.getPidController().getCacheSize() + " <dark_gray>items");
msg(sender, " <gray>待刷写数据: <red>" + plugin.getPidController().getDirtyQueueSize() + " <dark_gray>pending");
msg(sender, " <gray>TPS (1m): " + (tps > 18 ? "<green>" : "<red>") + String.format("%.2f", tps));
msg(sender, String.format(" <gray>JVM 内存: <aqua>%.0fMB <dark_gray>/ <gray>%.0fMB", usedMem, maxMem));
msg(sender, " <gray>活跃线程: <white>" + Thread.activeCount());
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleSIMD(CommandSender sender) {
msg(sender, "<yellow>⟳ 正在探测 CPU 指令集兼容性...");
var species = jdk.incubator.vector.DoubleVector.SPECIES_PREFERRED;
int lanes = species.length();
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:aqua:blue>SIMD 诊断报告</gradient>");
msg(sender, " <gray>Preferred Species: <white>" + species);
msg(sender, " <gray>Vector Width: <gold>" + (lanes * 64) + "-bit");
msg(sender, " <gray>并行通道数: <green>" + lanes + " <dark_gray>(doubles per cycle)");
String tech = lanes >= 8 ? "AVX-512" : lanes >= 4 ? "AVX2/AVX" : "SSE/Neon";
msg(sender, " <gray>硬件加速级别: <yellow>" + tech);
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleHealth(CommandSender sender) {
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:green:lime>系统健康普查</gradient>");
boolean db = plugin.getDatabaseManager().getDataSource() != null && !plugin.getDatabaseManager().getDataSource().isClosed();
msg(sender, " <gray>数据库连接: " + (db ? "<green>健康" : "<red>离线"));
int shops = plugin.getIntegrationManager().getMonitoredItems().size();
msg(sender, " <gray>商店映射: <white>" + (shops > 0 ? "<green>已挂载 (" + shops + ")" : "<red>无数据"));
int pidItems = plugin.getPidController().getCacheSize();
msg(sender, " <gray>计算内核: " + (pidItems > 0 ? "<green>活动中" : "<yellow>空闲"));
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleInspect(CommandSender sender, String[] args) {
if (args.length < 2) {
msg(sender, "<red>用法: /eb inspect <shopId_productId>");
return;
}
String itemId = args[1];
var state = plugin.getPidController().inspectState(itemId);
if (state == null) {
msg(sender, "<red>✗ 物品 [<white>" + itemId + "<red>] 尚未进入 PID 缓存。");
return;
}
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:aqua:blue>PID 运行快照</gradient> <dark_gray>» <white>" + itemId);
msg(sender, String.format(" <gray>Integral (积分): <aqua>%.4f", state.integral()));
msg(sender, String.format(" <gray>Last Error (误差): <red>%.4f", state.lastError()));
msg(sender, String.format(" <gray>Lambda (系数): <green>%.5f", state.lastLambda()));
msg(sender, " <gray>最后更新: <white>" + ((System.currentTimeMillis() - state.updateTime()) / 1000) + "s 前");
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleCheck(CommandSender sender, String[] args) {
Player target = (args.length > 1) ? Bukkit.getPlayer(args[1]) : (sender instanceof Player p ? p : null);
if (target == null) {
msg(sender, "<red>✗ 请指定一名在线玩家。");
return;
}
MarketManager mm = plugin.getMarketManager();
double p = mm.calculatePersonalFactor(target);
double f = mm.getMarketFlux();
double h = mm.getHolidayFactor();
double a = mm.getActivity();
double i = mm.getInflation();
double total = p * f * h * a * i;
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
msg(sender, "<gradient:gold:yellow>经济因子分析</gradient> <dark_gray>» <white>" + target.getName());
msg(sender, String.format(" <gray>个人/通胀: <aqua>%.2f <dark_gray>/ <gold>%.2f", p, i));
msg(sender, String.format(" <gray>环境/活跃: <light_purple>%.2f <dark_gray>/ <dark_aqua>%.2f", h, a));
msg(sender, String.format(" <gray>市场波动: <blue>%.2f", f));
msg(sender, "<yellow>➔ 最终全局倍率: <green><bold>" + String.format("%.4f", total));
msg(sender, "<dark_gray><st>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━");
}
private void handleBenchmark(CommandSender sender, String[] args) {
if (args.length < 2 || !args[1].equalsIgnoreCase("confirm")) {
msg(sender, "<yellow>⚠ 该操作将瞬时产生高负载。请输入 <gold>/eb benchmark confirm <yellow>确认。");
return;
}
msg(sender, "<aqua>正在启动 5,000,000 次 PID 模拟迭代测试...");
}
private void handleSave(CommandSender sender) {
int dirty = plugin.getPidController().getDirtyQueueSize();
if (dirty == 0) {
msg(sender, "<gray>没有需要刷写的脏数据。");
return;
}
msg(sender, "<yellow>正在手动刷写 " + dirty + " 条数据...");
plugin.getPidController().flushBuffer(true);
msg(sender, "<green>数据已安全持久化至数据库。");
}
@Override
public @Nullable List<String> onTabComplete(@NotNull CommandSender sender, @NotNull Command command, @NotNull String label, @NotNull String[] args) {
if (args.length == 1) {
return filter(args[0], Arrays.asList("reload", "check", "inspect", "save", "perf", "simd", "health", "benchmark", "help"));
}
if (args.length == 2) {
if (args[0].equalsIgnoreCase("check")) return null;
if (args[0].equalsIgnoreCase("inspect")) return filter(args[1], plugin.getIntegrationManager().getMonitoredItems());
}
return Collections.emptyList();
}
private List<String> filter(String input, List<String> list) {
return list.stream().filter(s -> s.toLowerCase().startsWith(input.toLowerCase())).collect(Collectors.toList());
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\EcoBridgeExpansion.java
==================================================

package top.ellan.ecobridge;
import me.clip.placeholderapi.expansion.PlaceholderExpansion;
import org.bukkit.OfflinePlayer;
import org.jetbrains.annotations.NotNull;
import java.util.concurrent.ConcurrentHashMap;
public class EcoBridgeExpansion extends PlaceholderExpansion {
private final EcoBridge plugin;
private final ConcurrentHashMap<String, CachedValue> personalFactorCache = new ConcurrentHashMap<>();
private static final long CACHE_TTL_MS = 1000;
private long lastCacheCleanup = System.currentTimeMillis();
private static class CachedValue {
final double value;
final long timestamp;
CachedValue(double value) {
this.value = value;
this.timestamp = System.currentTimeMillis();
}
boolean isExpired() {
return System.currentTimeMillis() - timestamp > CACHE_TTL_MS;
}
}
public EcoBridgeExpansion(EcoBridge plugin) {
this.plugin = plugin;
}
@Override
public @NotNull String getIdentifier() {
return "eco";
}
@Override
public @NotNull String getAuthor() {
return "Ellan";
}
@Override
public @NotNull String getVersion() {
return "2.0.0";
}
@Override
public boolean persist() {
return true;
}
@Override
public String onRequest(OfflinePlayer player, @NotNull String params) {
if (!plugin.isEnabled()) return "Loading...";
MarketManager market = plugin.getMarketManager();
if (market == null) return "Error";
cleanupCache();
return switch (params.toLowerCase()) {
case "inflation" -> formatDecimal(market.getInflation(), 4);
case "inflation_raw" -> String.valueOf(market.getInflation());
case "inflation_percent" -> formatPercent(market.getInflation() - 1.0);
case "flux" -> formatDecimal(market.getMarketFlux(), 4);
case "flux_raw" -> String.valueOf(market.getMarketFlux());
case "activity" -> formatDecimal(market.getActivity(), 4);
case "activity_raw" -> String.valueOf(market.getActivity());
case "threshold" -> formatInteger(market.getCurrentThreshold());
case "threshold_raw" -> String.valueOf(market.getCurrentThreshold());
case "threshold_k" -> formatThousands(market.getCurrentThreshold());
case "holiday" -> formatDecimal(market.getHolidayFactor(), 2);
case "holiday_raw" -> String.valueOf(market.getHolidayFactor());
case "holiday_percent" -> formatPercent(market.getHolidayFactor() - 1.0);
case "personal" -> getPersonalFactor(player, market, 4);
case "personal_raw" -> getPersonalFactor(player, market, -1);
case "final", "final_all" -> getFinalFactor(player, market, 4);
case "final_raw", "final_all_raw" -> getFinalFactor(player, market, -1);
case "final_percent" -> {
double factor = calculateFinalFactor(player, market);
yield formatPercent(factor - 1.0);
}
case "perf_simd_active" -> String.valueOf(plugin.getPerformanceMonitor() != null);
case "perf_memory_used" -> {
Runtime rt = Runtime.getRuntime();
long usedMB = (rt.totalMemory() - rt.freeMemory()) / 1048576;
yield usedMB + "MB";
}
case "perf_memory_percent" -> {
Runtime rt = Runtime.getRuntime();
double percent = 100.0 * (rt.totalMemory() - rt.freeMemory()) / rt.maxMemory();
yield formatPercent(percent / 100.0);
}
default -> {
PidController pid = plugin.getPidController();
if (pid == null) yield "N/A";
if (params.startsWith("pid_")) {
String itemId = params.substring(4);
double lambda = pid.getLambdaByString(itemId);
yield formatDecimal(lambda, 5);
}
if (params.startsWith("pid_raw_")) {
String itemId = params.substring(8);
double lambda = pid.getLambdaByString(itemId);
yield String.valueOf(lambda);
}
yield null;
}
};
}
private void cleanupCache() {
long now = System.currentTimeMillis();
if (now - lastCacheCleanup > 5000) {
personalFactorCache.entrySet().removeIf(entry -> entry.getValue().isExpired());
lastCacheCleanup = now;
}
}
private String getPersonalFactor(OfflinePlayer player, MarketManager market, int decimals) {
if (player == null) return decimals < 0 ? "1.0" : "1.0000";
String uuid = player.getUniqueId().toString();
CachedValue cached = personalFactorCache.get(uuid);
if (cached != null && !cached.isExpired()) {
return decimals < 0 ? String.valueOf(cached.value) :
String.format("%." + decimals + "f", cached.value);
}
if (player.isOnline()) {
double factor = market.calculatePersonalFactor(player.getPlayer());
personalFactorCache.put(uuid, new CachedValue(factor));
return decimals < 0 ? String.valueOf(factor) :
String.format("%." + decimals + "f", factor);
}
return decimals < 0 ? "1.0" : "1.0000";
}
private String getFinalFactor(OfflinePlayer player, MarketManager market, int decimals) {
double factor = calculateFinalFactor(player, market);
return decimals < 0 ? String.valueOf(factor) :
String.format("%." + decimals + "f", factor);
}
private double calculateFinalFactor(OfflinePlayer player, MarketManager market) {
double personal = 1.0;
if (player != null && player.isOnline()) {
String uuid = player.getUniqueId().toString();
CachedValue cached = personalFactorCache.get(uuid);
if (cached != null && !cached.isExpired()) {
personal = cached.value;
} else {
personal = market.calculatePersonalFactor(player.getPlayer());
personalFactorCache.put(uuid, new CachedValue(personal));
}
}
return personal
* market.getMarketFlux()
* market.getHolidayFactor()
* market.getActivity()
* market.getInflation();
}
private String formatDecimal(double value, int decimals) {
return String.format("%." + decimals + "f", value);
}
private String formatInteger(double value) {
return String.format("%,.0f", value);
}
private String formatThousands(double value) {
if (value >= 1_000_000) {
return String.format("%.1fM", value / 1_000_000);
} else if (value >= 1_000) {
return String.format("%.1fK", value / 1_000);
} else {
return String.format("%.0f", value);
}
}
private String formatPercent(double ratio) {
return String.format("%.1f%%", ratio * 100);
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\IntegrationManager.java
==================================================

package top.ellan.ecobridge;
import cn.superiormc.ultimateshop.api.ShopHelper;
import cn.superiormc.ultimateshop.managers.ConfigManager;
import cn.superiormc.ultimateshop.objects.ObjectShop;
import cn.superiormc.ultimateshop.objects.buttons.ObjectItem;
import cn.superiormc.ultimateshop.objects.caches.ObjectUseTimesCache;
import org.bukkit.Bukkit;
import java.util.*;
public class IntegrationManager {
private record ItemEntry(
String rawId,
int pidHandle,
ObjectItem item
) {}
private final EcoBridge plugin;
private volatile List<ItemEntry> activeEntries = Collections.emptyList();
private volatile List<String> monitoredIdCache = Collections.emptyList();
private final Map<Integer, Double> lastTotalVolumes = new HashMap<>(4096);
public IntegrationManager(EcoBridge plugin) {
this.plugin = plugin;
}
public void collectDataAndCalculate() {
final List<ItemEntry> currentItems = this.activeEntries;
if (currentItems.isEmpty()) {
if (Bukkit.getPluginManager().isPluginEnabled("UltimateShop")) {
syncShops();
if (activeEntries.isEmpty()) return;
} else {
return;
}
}
final int size = currentItems.size();
int[] handles = new int[size];
double[] deltaVolumes = new double[size];
int count = 0;
for (int i = 0; i < size; i++) {
ItemEntry entry = currentItems.get(i);
try {
ObjectUseTimesCache cache = ShopHelper.getServerUseTimesCache(entry.item());
if (cache != null) {
double currentTotal = cache.getBuyUseTimes() + cache.getSellUseTimes();
double lastTotal = lastTotalVolumes.getOrDefault(entry.pidHandle(), currentTotal);
double delta = currentTotal - lastTotal;
lastTotalVolumes.put(entry.pidHandle(), currentTotal);
handles[count] = entry.pidHandle();
deltaVolumes[count] = delta;
count++;
}
} catch (Exception ignored) {
}
}
if (count == 0) return;
final int finalCount = count;
final int[] finalHandles = (count == size) ? handles : Arrays.copyOf(handles, count);
final double[] finalDeltas = (count == size) ? deltaVolumes : Arrays.copyOf(deltaVolumes, count);
if (plugin.getPidController() != null) {
plugin.getPidController().calculateBatch(finalHandles, finalDeltas, finalCount);
}
}
public synchronized void syncShops() {
if (!Bukkit.getPluginManager().isPluginEnabled("UltimateShop") ||
ConfigManager.configManager == null ||
ConfigManager.configManager.shopConfigs == null) {
return;
}
Map<String, ObjectShop> shopMap = ConfigManager.configManager.shopConfigs;
if (shopMap.isEmpty()) return;
List<ItemEntry> newEntries = new ArrayList<>(shopMap.size() * 10);
List<String> newIds = new ArrayList<>(shopMap.size() * 10);
PidController pidCtrl = plugin.getPidController();
if (pidCtrl == null) return;
for (Map.Entry<String, ObjectShop> entry : shopMap.entrySet()) {
String shopId = entry.getKey();
ObjectShop shop = entry.getValue();
if (shop == null) continue;
List<ObjectItem> productList = shop.getProductList();
if (productList == null) continue;
for (ObjectItem item : productList) {
String productId = item.getProduct();
if (productId == null || productId.isEmpty()) continue;
String rawId = shopId + "_" + productId;
int handle = pidCtrl.getHandle(rawId);
newEntries.add(new ItemEntry(rawId, handle, item));
newIds.add(rawId);
ObjectUseTimesCache cache = ShopHelper.getServerUseTimesCache(item);
if (cache != null) {
double currentTotal = cache.getBuyUseTimes() + cache.getSellUseTimes();
lastTotalVolumes.put(handle, currentTotal);
}
}
}
this.activeEntries = newEntries;
this.monitoredIdCache = Collections.unmodifiableList(newIds);
plugin.getLogger().info("[Integration] Synced " + activeEntries.size() + " items from UltimateShop.");
}
public List<String> getMonitoredItems() {
return monitoredIdCache;
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\MarketManager.java
==================================================

package top.ellan.ecobridge;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.bukkit.Bukkit;
import org.bukkit.Statistic;
import org.bukkit.entity.Player;
import su.nightexpress.coinsengine.CoinsEnginePlugin;
import su.nightexpress.coinsengine.api.CoinsEngineAPI;
import su.nightexpress.coinsengine.api.currency.Currency;
import su.nightexpress.coinsengine.tops.TopEntry;
import su.nightexpress.coinsengine.tops.TopManager;
import java.net.URI;
import java.net.http.HttpClient;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.time.DayOfWeek;
import java.time.Duration;
import java.time.LocalDate;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicReference;
public class MarketManager {
private final EcoBridge plugin;
private final ExecutorService ioExecutor = Executors.newVirtualThreadPerTaskExecutor();
private final AtomicReference<Double> inflation = new AtomicReference<>(1.0);
private final AtomicReference<Double> marketFlux = new AtomicReference<>(1.0);
private final AtomicReference<Double> currentThreshold = new AtomicReference<>(100000.0);
private final AtomicReference<Double> activityFactor = new AtomicReference<>(1.0);
private final ConcurrentHashMap<String, Integer> holidayCache = new ConcurrentHashMap<>();
private final ConcurrentHashMap<UUID, Map.Entry<Integer, Long>> statCache = new ConcurrentHashMap<>();
private volatile long lastHolidayUpdate = 0;
private final HttpClient httpClient;
private final ObjectMapper jsonMapper = new ObjectMapper();
private CoinsEnginePlugin coinsEnginePlugin;
private Currency currency;
private static final double MIN_THRESH = 100000.0;
private static final double INF_WEIGHT = 0.3;
private static final double PERCENTILE = 0.15;
private static final String HOLIDAY_API_URL = "https:
public MarketManager(EcoBridge plugin) {
this.plugin = plugin;
this.httpClient = HttpClient.newBuilder()
.version(HttpClient.Version.HTTP_2)
.connectTimeout(Duration.ofSeconds(10))
.executor(ioExecutor)
.build();
setupCoinsEngine();
}
private void setupCoinsEngine() {
if (Bukkit.getPluginManager().isPluginEnabled("CoinsEngine") && CoinsEngineAPI.isLoaded()) {
this.coinsEnginePlugin = CoinsEngineAPI.plugin();
String currencyId = plugin.getConfig().getString("economy-settings.currency-id", "money");
this.currency = CoinsEngineAPI.getCurrency(currencyId);
if (this.currency != null) {
plugin.getLogger().info("[Market] Hooked into CoinsEngine. Currency: " + currencyId);
if (!coinsEnginePlugin.getTopManager().isPresent()) {
plugin.getLogger().warning("[Market] CoinsEngine 'Top' feature is disabled in config!");
plugin.getLogger().warning("[Market] Inflation calculation will be skipped.");
}
} else {
plugin.getLogger().warning("[Market] Currency '" + currencyId + "' not found in CoinsEngine!");
}
} else {
plugin.getLogger().warning("[Market] CoinsEngine plugin not found or API not loaded!");
}
}
public void updateEconomyMetrics() {
if (currency == null || coinsEnginePlugin == null) return;
ioExecutor.submit(() -> {
try {
Optional<TopManager> topManagerOpt = coinsEnginePlugin.getTopManager();
if (topManagerOpt.isEmpty()) return;
TopManager topManager = topManagerOpt.get();
List<TopEntry> entries = topManager.getTopEntries(currency);
if (entries.isEmpty()) return;
int totalPlayers = entries.size();
int thresholdIndex = (int) Math.floor(totalPlayers * PERCENTILE);
thresholdIndex = Math.max(0, Math.min(totalPlayers - 1, thresholdIndex));
TopEntry thresholdEntry = entries.get(thresholdIndex);
double threshold = Math.max(thresholdEntry.getBalance(), MIN_THRESH);
currentThreshold.set(threshold);
double ratio = Math.max(1.0, threshold / MIN_THRESH);
double newInflation = 1.0 + (Math.log(ratio) * INF_WEIGHT);
inflation.set(newInflation);
cleanupStatCache();
plugin.getLogger().info(String.format(
"[Market] Metrics updated via CoinsEngine: Players=%d, Thresh=%.0f, Inf=%.4f",
totalPlayers, threshold, newInflation
));
} catch (Exception e) {
plugin.getLogger().warning("[Market] Metrics update failed: " + e.getMessage());
}
});
}
public double calculatePersonalFactor(Player player) {
if (player.isOp()) return 1.0;
double minFactor = plugin.getConfig().getDouble("personal-factor.min-factor", 0.5);
double maxTax = plugin.getConfig().getDouble("personal-factor.rich.max-tax", 0.1);
double currentFactor = 1.0;
if (currency != null) {
double balance = CoinsEngineAPI.getBalance(player.getUniqueId(), currency);
double threshold = currentThreshold.get();
if (balance > threshold) {
double excess = balance - threshold;
double tax = Math.log10(excess + 10) * (maxTax / 10.0);
currentFactor += Math.min(tax, maxTax * 2);
}
}
int ticksPlayed = getCachedStatistic(player, Statistic.PLAY_ONE_MINUTE);
if (ticksPlayed > 0) {
double vetMax = plugin.getConfig().getDouble("personal-factor.veteran.max-discount", 0.05);
int vetHours = plugin.getConfig().getInt("personal-factor.veteran.threshold-hours", 100);
double discount = (double) ticksPlayed / (vetHours * 72000L) * vetMax;
currentFactor -= Math.min(discount, vetMax);
}
return Math.max(minFactor, currentFactor);
}
private int getCachedStatistic(Player player, Statistic stat) {
UUID uid = player.getUniqueId();
Map.Entry<Integer, Long> entry = statCache.get(uid);
long now = System.currentTimeMillis();
if (entry != null && (now - entry.getValue() < 300_000)) {
return entry.getKey();
}
if (Bukkit.isPrimaryThread()) {
int val = player.getStatistic(stat);
statCache.put(uid, Map.entry(val, now));
return val;
} else {
Bukkit.getScheduler().runTask(plugin, () -> {
if (player.isOnline()) {
statCache.put(uid, Map.entry(player.getStatistic(stat), System.currentTimeMillis()));
}
});
return entry != null ? entry.getKey() : 0;
}
}
private void cleanupStatCache() {
long now = System.currentTimeMillis();
statCache.entrySet().removeIf(e -> (now - e.getValue().getValue() > 600_000));
}
public void updateMarketFlux() {
long currentHour = System.currentTimeMillis() / 3600000L;
Random rng = new Random(currentHour + "Salt".hashCode());
double range = plugin.getConfig().getDouble("market-flux.normal-range", 0.05);
if (rng.nextDouble() < plugin.getConfig().getDouble("market-flux.event-chance", 0.1)) {
range = plugin.getConfig().getDouble("market-flux.event-range", 0.3);
}
double rawFlux = 1.0 + ((rng.nextDouble() * 2.0 - 1.0) * range);
marketFlux.set(Math.floor(rawFlux * inflation.get() * 10000) / 10000.0);
}
public void updateActivityFactor() {
Bukkit.getScheduler().runTask(plugin, () -> {
int online = Bukkit.getOnlinePlayers().size();
double tps = Bukkit.getTPS()[0];
ioExecutor.submit(() -> {
double base = plugin.getConfig().getDouble("activity.base", 1.0);
double impact = plugin.getConfig().getDouble("activity.player-impact", 0.001);
double factor = base + (online * impact);
double tpsLimit = plugin.getConfig().getDouble("activity.tps-limit", 18.0);
if (tps < tpsLimit) {
double penalty = (20.0 - tps) * plugin.getConfig().getDouble("activity.tps-weight", 0.05);
factor = Math.max(0.1, factor - penalty);
}
activityFactor.set(factor);
});
});
}
public void updateHolidayCache() {
if (System.currentTimeMillis() - lastHolidayUpdate < 86400000) return;
int year = LocalDate.now().getYear();
HttpRequest request = HttpRequest.newBuilder()
.uri(URI.create(HOLIDAY_API_URL + "?year=" + year))
.header("User-Agent", "EcoBridge/Paper")
.timeout(Duration.ofSeconds(5))
.GET()
.build();
httpClient.sendAsync(request, HttpResponse.BodyHandlers.ofString())
.thenAccept(res -> {
if (res.statusCode() == 200) {
try {
JsonNode root = jsonMapper.readTree(res.body());
if (root.path("data").isArray()) {
holidayCache.clear();
for (JsonNode node : root.get("data")) {
holidayCache.put(node.get("date").asText(), node.get("type").asInt());
}
lastHolidayUpdate = System.currentTimeMillis();
}
} catch (Exception ignored) {}
}
});
}
public double getHolidayFactor() {
String dateKey = LocalDate.now().toString();
Integer type = holidayCache.get(dateKey);
if (type != null) {
return switch (type) {
case 0 -> plugin.getConfig().getDouble("holidays.workday", 1.0);
case 1 -> plugin.getConfig().getDouble("holidays.weekend", 1.1);
case 2 -> plugin.getConfig().getDouble("holidays.holiday", 1.5);
default -> 1.0;
};
}
DayOfWeek day = LocalDate.now().getDayOfWeek();
return (day == DayOfWeek.SATURDAY || day == DayOfWeek.SUNDAY)
? plugin.getConfig().getDouble("holidays.weekend", 1.1)
: 1.0;
}
public void shutdown() {
ioExecutor.shutdownNow();
}
public double getInflation() { return inflation.get(); }
public double getMarketFlux() { return marketFlux.get(); }
public double getActivity() { return activityFactor.get(); }
public double getCurrentThreshold() { return currentThreshold.get(); }
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\PerformanceMonitor.java
==================================================

package top.ellan.ecobridge;
import jdk.incubator.vector.DoubleVector;
import jdk.incubator.vector.VectorSpecies;
import org.bukkit.Bukkit;
import org.bukkit.scheduler.BukkitTask;
import java.lang.management.*;
import java.util.List;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.LongAdder;
public class PerformanceMonitor {
private final EcoBridge plugin;
private final ScheduledExecutorService scheduler;
private BukkitTask syncCacheTask;
private final LongAdder totalCalculations = new LongAdder();
private final LongAdder simdCalculations = new LongAdder();
private final LongAdder scalarCalculations = new LongAdder();
private final LongAdder dbWrites = new LongAdder();
private final LongAdder dbReads = new LongAdder();
private final ConcurrentHashMap<String, PerformanceCounter> counters = new ConcurrentHashMap<>();
private final MemoryMXBean memoryBean = ManagementFactory.getMemoryMXBean();
private final ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();
private GarbageCollectorMXBean youngGC;
private GarbageCollectorMXBean oldGC;
private volatile double[] cachedTps = new double[]{20.0, 20.0, 20.0};
private volatile int cachedPlayerCount = 0;
private final int logInterval;
private volatile long simdBandwidth = 0;
private volatile int vectorLanes = 0;
public PerformanceMonitor(EcoBridge plugin) {
this.plugin = plugin;
this.logInterval = plugin.getConfig().getInt("monitoring.log-interval", 300);
detectGCBeans();
this.scheduler = Executors.newSingleThreadScheduledExecutor(
r -> Thread.ofVirtual().name("EcoBridge-Monitor").unstarted(r)
);
this.syncCacheTask = Bukkit.getScheduler().runTaskTimer(plugin, this::updateServerStateCache, 100L, 100L);
benchmarkSIMD();
startMonitoring();
}
private void updateServerStateCache() {
try {
double[] tps = Bukkit.getTPS();
if (tps != null) {
this.cachedTps = tps;
}
this.cachedPlayerCount = Bukkit.getOnlinePlayers().size();
} catch (Throwable ignored) {}
}
private void detectGCBeans() {
List<GarbageCollectorMXBean> gcBeans = ManagementFactory.getGarbageCollectorMXBeans();
for (GarbageCollectorMXBean bean : gcBeans) {
String name = bean.getName().toLowerCase();
if (name.contains("young") || name.contains("eden") || name.contains("copy") || name.contains("scavenge")) {
youngGC = bean;
} else if (name.contains("old") || name.contains("tenured") || name.contains("mark") || name.contains("global")) {
oldGC = bean;
} else if (name.contains("g1")) {
if (name.contains("young")) youngGC = bean; else oldGC = bean;
} else if (name.contains("shenandoah") || name.contains("zgc")) {
oldGC = bean;
}
}
}
private void benchmarkSIMD() {
Thread.ofVirtual().start(() -> {
try {
VectorSpecies<Double> species = DoubleVector.SPECIES_PREFERRED;
vectorLanes = species.length();
int size = 1024 * 1024;
double[] data = new double[size];
for (int i = 0; i < 50; i++) vectorAdd(data, species);
long startNs = System.nanoTime();
int iterations = 100;
for (int i = 0; i < iterations; i++) vectorAdd(data, species);
long elapsedNs = System.nanoTime() - startNs;
long bytesProcessed = (long) size * 8L * iterations;
double seconds = elapsedNs / 1e9;
simdBandwidth = (long) (bytesProcessed / seconds / 1e9);
plugin.getLogger().info(String.format("[Perf] SIMD Active: %s (%d lanes), BW: %d GB/s",
species, vectorLanes, simdBandwidth));
} catch (Throwable e) {
plugin.getLogger().warning("[Perf] SIMD unavailable: " + e.getMessage());
}
});
}
private void vectorAdd(double[] data, VectorSpecies<Double> species) {
int i = 0;
int bound = species.loopBound(data.length);
for (; i < bound; i += species.length()) {
DoubleVector.fromArray(species, data, i).add(1.0).intoArray(data, i);
}
}
private void startMonitoring() {
scheduler.scheduleAtFixedRate(this::logPerformanceReport, logInterval, logInterval, TimeUnit.SECONDS);
}
private void logPerformanceReport() {
try {
StringBuilder report = new StringBuilder();
report.append("\n§8[§aEcoBridge§8] §7Performance Diagnostics\n");
long total = totalCalculations.sum();
long simd = simdCalculations.sum();
double ratio = total > 0 ? (100.0 * simd / total) : 0.0;
report.append(String.format(" §7SIMD: §f%d lanes §7| Ratio: §a%.1f%%\n", vectorLanes, ratio));
MemoryUsage heap = memoryBean.getHeapMemoryUsage();
long used = heap.getUsed() / 1048576;
long max = heap.getMax() / 1048576;
report.append(String.format(" §7Mem: §e%dMB/%dMB §7| Threads: §f%d\n",
used, max, threadBean.getThreadCount()));
if (youngGC != null) {
report.append(String.format(" §7GC(Young): §f%d runs §7| §e%dms\n",
youngGC.getCollectionCount(), youngGC.getCollectionTime()));
}
if (oldGC != null) {
report.append(String.format(" §7GC(Old):   §f%d runs §7| §c%dms\n",
oldGC.getCollectionCount(), oldGC.getCollectionTime()));
}
report.append(String.format(" §7TPS: §a%.1f §7| Players: §f%d\n", cachedTps[0], cachedPlayerCount));
report.append(String.format(" §7DB IO: §fW:%,d R:%,d\n", dbWrites.sumThenReset(), dbReads.sumThenReset()));
if (!counters.isEmpty()) {
report.append(" §7Hotspots:\n");
counters.forEach((k, v) -> {
if (v.getCount() > 0) {
report.append(String.format("  - %s: §e%.3fms\n", k, v.getAverageMs()));
}
});
}
plugin.getLogger().info(report.toString());
totalCalculations.reset();
simdCalculations.reset();
scalarCalculations.reset();
} catch (Exception e) {
plugin.getLogger().warning("Error generating perf report: " + e.getMessage());
}
}
public static class PerformanceCounter {
private final AtomicLong totalNs = new AtomicLong(0);
private final AtomicLong count = new AtomicLong(0);
public void record(long nanoTime) {
totalNs.addAndGet(nanoTime);
count.incrementAndGet();
}
public double getAverageMs() {
long c = count.get();
return c > 0 ? (totalNs.get() / c / 1_000_000.0) : 0.0;
}
public long getCount() { return count.get(); }
}
public void recordCalculation(boolean usedSIMD) {
totalCalculations.increment();
if (usedSIMD) simdCalculations.increment(); else scalarCalculations.increment();
}
public void recordDbWrite() { dbWrites.increment(); }
public void recordDbRead() { dbReads.increment(); }
public void startTimer(String name) {
counters.computeIfAbsent(name, k -> new PerformanceCounter());
}
public void stopTimer(String name, long startNs) {
PerformanceCounter c = counters.get(name);
if (c != null) c.record(System.nanoTime() - startNs);
}
public void shutdown() {
if (syncCacheTask != null && !syncCacheTask.isCancelled()) {
syncCacheTask.cancel();
}
scheduler.shutdown();
try {
if (!scheduler.awaitTermination(2, TimeUnit.SECONDS)) scheduler.shutdownNow();
} catch (InterruptedException e) { scheduler.shutdownNow(); }
}
}

==================================================
FILE: EcoBridge_Project\src\main\java\top\ellan\ecobridge\PidController.java
==================================================

package top.ellan.ecobridge;
import jdk.incubator.vector.*;
import java.lang.foreign.*;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.locks.StampedLock;
public class PidController implements AutoCloseable {
private static final VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_PREFERRED;
private static final int V_LEN = SPECIES.length();
private static final int SEGMENT_BITS = 4;
private static final int SEGMENT_COUNT = 1 << SEGMENT_BITS;
private static final int SEGMENT_MASK = SEGMENT_COUNT - 1;
private static final int CAPACITY = 8192;
private static final int SLOT_MASK = 0xFFFF;
private static final ValueLayout.OfDouble D_LAYOUT = ValueLayout.JAVA_DOUBLE;
private static final ValueLayout.OfLong L_LAYOUT = ValueLayout.JAVA_LONG;
private static final ValueLayout.OfByte B_LAYOUT = ValueLayout.JAVA_BYTE;
private static final long D_SIZE = 8L;
private static final DoubleVector V_TARGET     = DoubleVector.broadcast(SPECIES, 1000.0);
private static final DoubleVector V_DEADBAND   = DoubleVector.broadcast(SPECIES, 20.0);
private static final DoubleVector V_NEG_TAU_INV = DoubleVector.broadcast(SPECIES, -0.00001929);
private static final DoubleVector V_KP         = DoubleVector.broadcast(SPECIES, 0.00001);
private static final DoubleVector V_KP_NEG     = DoubleVector.broadcast(SPECIES, 0.00001 * 0.6);
private static final DoubleVector V_KI         = DoubleVector.broadcast(SPECIES, 0.000001);
private static final DoubleVector V_KD         = DoubleVector.broadcast(SPECIES, 0.00005);
private static final DoubleVector V_BASE       = DoubleVector.broadcast(SPECIES, 0.002);
private static final DoubleVector V_ALPHA      = DoubleVector.broadcast(SPECIES, 0.05);
private static final DoubleVector V_BETA       = DoubleVector.broadcast(SPECIES, 0.95);
private static final DoubleVector V_ZERO       = DoubleVector.broadcast(SPECIES, 0.0);
private static final DoubleVector V_ONE        = DoubleVector.broadcast(SPECIES, 1.0);
private static final DoubleVector V_I_MAX      = DoubleVector.broadcast(SPECIES, 30000.0);
private static final DoubleVector V_I_MIN      = DoubleVector.broadcast(SPECIES, -30000.0);
private static final DoubleVector V_L_MAX      = DoubleVector.broadcast(SPECIES, 0.01);
private static final DoubleVector V_L_MIN      = DoubleVector.broadcast(SPECIES, 0.0005);
private static final DoubleVector V_DT_MAX     = DoubleVector.broadcast(SPECIES, 1.0);
private static final DoubleVector V_DT_MIN     = DoubleVector.broadcast(SPECIES, 0.05);
private final EcoBridge plugin;
private final Arena arena;
private final Segment[] segments;
private final ConcurrentHashMap<String, Integer> registry = new ConcurrentHashMap<>(4096);
private final AtomicBoolean closed = new AtomicBoolean(false);
private final ThreadLocal<CalcContext> tlContext = ThreadLocal.withInitial(CalcContext::new);
public PidController(EcoBridge plugin) {
this.plugin = plugin;
this.arena = Arena.ofShared();
this.segments = new Segment[SEGMENT_COUNT];
for (int i = 0; i < SEGMENT_COUNT; i++) {
this.segments[i] = new Segment(arena);
}
plugin.getLogger().info("[PID] Ultimate Optimized Controller Initialized. Vector Lane: " + V_LEN);
}
public int getHandle(String itemId) {
return registry.computeIfAbsent(itemId, id -> {
int hash = Math.abs(id.hashCode());
int segId = hash & SEGMENT_MASK;
Segment seg = segments[segId];
long stamp = seg.lock.writeLock();
try {
int slot = seg.allocateSlot();
if (slot < 0) {
plugin.getLogger().warning("[PID] Segment " + segId + " overflow!");
return -1;
}
return (segId << 16) | slot;
} finally {
seg.lock.unlockWrite(stamp);
}
});
}
public double getLambdaByString(String itemId) {
Integer handle = registry.get(itemId);
if (handle == null) return 0.002;
int segId = handle >>> 16;
int slot = handle & SLOT_MASK;
Segment seg = segments[segId];
long offset = (long) slot * D_SIZE;
long stamp = seg.lock.tryOptimisticRead();
double lambda = seg.lambdas.get(D_LAYOUT, offset);
if (!seg.lock.validate(stamp)) {
stamp = seg.lock.readLock();
try {
lambda = seg.lambdas.get(D_LAYOUT, offset);
} finally {
seg.lock.unlockRead(stamp);
}
}
return lambda;
}
public void calculateBatch(int[] handles, double[] volumes, int count) {
if (closed.get() || count == 0) return;
CalcContext ctx = tlContext.get();
ctx.reset();
for (int i = 0; i < count; i++) {
int h = handles[i];
if (h == -1) continue;
int segId = h >>> 16;
int slot = h & SLOT_MASK;
ctx.push(segId, slot, volumes[i]);
}
long now = System.currentTimeMillis();
for (int i = 0; i < SEGMENT_COUNT; i++) {
if (ctx.counts[i] > 0) {
processSegment(segments[i], ctx, i, now);
}
}
}
private void processSegment(Segment seg, CalcContext ctx, int segId, long now) {
int count = ctx.counts[segId];
int[] slots = ctx.segSlots[segId];
double[] vols = ctx.segVols[segId];
long stamp = seg.lock.writeLock();
try {
MemorySegment msInt = seg.integrals;
MemorySegment msErr = seg.errors;
MemorySegment msLam = seg.lambdas;
MemorySegment msTime = seg.times;
MemorySegment msDirty = seg.dirty;
int i = 0;
int loopBound = SPECIES.loopBound(count);
double[] vBuf = ctx.vBufState;
for (; i < loopBound; i += V_LEN) {
for (int lane = 0; lane < V_LEN; lane++) {
int slotIdx = slots[i + lane];
long offset = (long) slotIdx * D_SIZE;
vBuf[lane]             = msInt.get(D_LAYOUT, offset);
vBuf[lane + V_LEN]     = msErr.get(D_LAYOUT, offset);
vBuf[lane + 2 * V_LEN] = msLam.get(D_LAYOUT, offset);
long lastT             = msTime.get(L_LAYOUT, offset);
vBuf[lane + 3 * V_LEN] = (now - lastT) * 0.001;
}
DoubleVector vIntegral = DoubleVector.fromArray(SPECIES, vBuf, 0);
DoubleVector vLastErr  = DoubleVector.fromArray(SPECIES, vBuf, V_LEN);
DoubleVector vLambda   = DoubleVector.fromArray(SPECIES, vBuf, 2 * V_LEN);
DoubleVector vDt       = DoubleVector.fromArray(SPECIES, vBuf, 3 * V_LEN);
DoubleVector vVol      = DoubleVector.fromArray(SPECIES, vols, i);
vDt = vDt.max(V_DT_MIN).min(V_DT_MAX);
DoubleVector vErrRaw = vVol.sub(V_TARGET);
VectorMask<Double> maskDead = vErrRaw.abs().compare(VectorOperators.LT, V_DEADBAND);
DoubleVector vErr = vErrRaw.blend(V_ZERO, maskDead);
DoubleVector vD_Part = vErr.sub(vLastErr).div(vDt);
DoubleVector vDecay = vDt.fma(V_NEG_TAU_INV, V_ONE);
vIntegral = vIntegral.mul(vDecay);
vIntegral = vErr.fma(vDt, vIntegral);
vIntegral = vIntegral.max(V_I_MIN).min(V_I_MAX);
VectorMask<Double> maskNeg = vErr.compare(VectorOperators.LT, V_ZERO);
DoubleVector vKp = V_KP.blend(V_KP_NEG, maskNeg);
DoubleVector vP = vErr.mul(vKp);
DoubleVector vD = vD_Part.mul(V_KD);
DoubleVector vI = vIntegral.mul(V_KI);
DoubleVector vRaw = vP.add(vI).add(vD).add(V_BASE);
vLambda = vLambda.fma(V_BETA, vRaw.mul(V_ALPHA));
vLambda = vLambda.max(V_L_MIN).min(V_L_MAX);
vIntegral.intoArray(vBuf, 0);
vErr.intoArray(vBuf, V_LEN);
vLambda.intoArray(vBuf, 2 * V_LEN);
for (int lane = 0; lane < V_LEN; lane++) {
int slotIdx = slots[i + lane];
long offset = (long) slotIdx * D_SIZE;
msInt.set(D_LAYOUT, offset, vBuf[lane]);
msErr.set(D_LAYOUT, offset, vBuf[lane + V_LEN]);
msLam.set(D_LAYOUT, offset, vBuf[lane + 2 * V_LEN]);
msTime.set(L_LAYOUT, offset, now);
msDirty.set(B_LAYOUT, (long) slotIdx, (byte) 1);
}
}
for (; i < count; i++) {
int slotIdx = slots[i];
long offset = (long) slotIdx * D_SIZE;
double dt = (now - msTime.get(L_LAYOUT, offset)) * 0.001;
dt = Math.max(0.05, Math.min(1.0, dt));
double integral = msInt.get(D_LAYOUT, offset);
integral *= (1.0 - dt * 0.00001929);
double vol = vols[i];
double err = vol - 1000.0;
if (Math.abs(err) < 20.0) err = 0.0;
double kp = (err < 0) ? 0.000006 : 0.00001;
integral = Math.fma(err, dt, integral);
integral = Math.max(-30000, Math.min(30000, integral));
double lastErr = msErr.get(D_LAYOUT, offset);
double d = (err - lastErr) / dt * 0.00005;
double raw = kp * err + integral * 0.000001 + d + 0.002;
double lambda = msLam.get(D_LAYOUT, offset);
lambda = Math.fma(lambda, 0.95, raw * 0.05);
lambda = Math.max(0.0005, Math.min(0.01, lambda));
msInt.set(D_LAYOUT, offset, integral);
msErr.set(D_LAYOUT, offset, err);
msLam.set(D_LAYOUT, offset, lambda);
msTime.set(L_LAYOUT, offset, now);
msDirty.set(B_LAYOUT, (long) slotIdx, (byte) 1);
}
} finally {
seg.lock.unlockWrite(stamp);
}
}
private static class Segment {
@SuppressWarnings("unused")
long p01, p02, p03, p04, p05, p06, p07;
final StampedLock lock = new StampedLock();
@SuppressWarnings("unused")
long p11, p12, p13, p14, p15, p16, p17;
final MemorySegment integrals;
final MemorySegment errors;
final MemorySegment lambdas;
final MemorySegment times;
final MemorySegment dirty;
final BitSet allocationMap = new BitSet(CAPACITY);
Segment(Arena arena) {
integrals = arena.allocate(D_LAYOUT, CAPACITY);
errors = arena.allocate(D_LAYOUT, CAPACITY);
lambdas = arena.allocate(D_LAYOUT, CAPACITY);
times = arena.allocate(L_LAYOUT, CAPACITY);
dirty = arena.allocate(B_LAYOUT, CAPACITY);
warmup();
}
int allocateSlot() {
int slot = allocationMap.nextClearBit(0);
if (slot >= CAPACITY) return -1;
allocationMap.set(slot);
lambdas.setAtIndex(D_LAYOUT, slot, 0.002);
times.setAtIndex(L_LAYOUT, slot, System.currentTimeMillis());
return slot;
}
void warmup() {
for(int i=0; i<CAPACITY; i+=512) integrals.setAtIndex(D_LAYOUT, i, 0);
}
}
private static class CalcContext {
static final int INITIAL_CAPACITY = 512;
static final int MAX_CAPACITY = 1024 * 1024;
int[][] segSlots = new int[SEGMENT_COUNT][INITIAL_CAPACITY];
double[][] segVols = new double[SEGMENT_COUNT][INITIAL_CAPACITY];
final int[] counts = new int[SEGMENT_COUNT];
final double[] vBufState = new double[4 * V_LEN];
void reset() {
Arrays.fill(counts, 0);
}
void push(int segId, int slot, double vol) {
int idx = counts[segId]++;
if (idx >= segSlots[segId].length) {
grow(segId);
}
segSlots[segId][idx] = slot;
segVols[segId][idx] = vol;
}
private void grow(int segId) {
int oldCap = segSlots[segId].length;
if (oldCap >= MAX_CAPACITY) throw new OutOfMemoryError("PID Context buffer limit");
int newCap = oldCap + (oldCap >> 1);
if (newCap > MAX_CAPACITY) newCap = MAX_CAPACITY;
int[] newSlots = new int[newCap];
double[] newVols = new double[newCap];
System.arraycopy(segSlots[segId], 0, newSlots, 0, oldCap);
System.arraycopy(segVols[segId], 0, newVols, 0, oldCap);
segSlots[segId] = newSlots;
segVols[segId] = newVols;
}
}
@Override
public void close() {
if (closed.compareAndSet(false, true)) {
if (arena.scope().isAlive()) arena.close();
}
}
public int getCacheSize() {
return registry.size();
}
public int getDirtyQueueSize() {
int totalDirty = 0;
for (Segment seg : segments) {
long stamp = seg.lock.readLock();
try {
for (int i = seg.allocationMap.nextSetBit(0); i >= 0; i = seg.allocationMap.nextSetBit(i + 1)) {
if (seg.dirty.get(B_LAYOUT, (long) i) == (byte) 1) {
totalDirty++;
}
}
} finally {
seg.lock.unlockRead(stamp);
}
}
return totalDirty;
}
public void flushBuffer(boolean sync) {
if (closed.get()) return;
List<DatabaseManager.PidDbSnapshot> batch = new ArrayList<>();
for (int segId = 0; segId < SEGMENT_COUNT; segId++) {
Segment seg = segments[segId];
long stamp = seg.lock.writeLock();
try {
for (int i = seg.allocationMap.nextSetBit(0); i >= 0; i = seg.allocationMap.nextSetBit(i + 1)) {
if (seg.dirty.get(B_LAYOUT, (long) i) == (byte) 1) {
seg.dirty.set(B_LAYOUT, (long) i, (byte) 0);
int targetHandle = (segId << 16) | i;
String itemId = findIdByHandle(targetHandle);
if (itemId != null) {
long offset = (long) i * D_SIZE;
batch.add(new DatabaseManager.PidDbSnapshot(
itemId,
seg.integrals.get(D_LAYOUT, offset),
seg.errors.get(D_LAYOUT, offset),
seg.lambdas.get(D_LAYOUT, offset),
seg.times.get(L_LAYOUT, offset)
));
}
}
if (batch.size() >= 1000) break;
}
} finally {
seg.lock.unlockWrite(stamp);
}
if (batch.size() >= 1000) break;
}
if (batch.isEmpty()) return;
if (sync) {
plugin.getDatabaseManager().saveBatch(batch);
} else {
Thread.ofVirtual().start(() -> plugin.getDatabaseManager().saveBatch(batch));
}
}
public PidStateDto inspectState(String itemId) {
Integer handle = registry.get(itemId);
if (handle == null) return null;
int segId = handle >>> 16;
int slot = handle & SLOT_MASK;
Segment seg = segments[segId];
long offset = (long) slot * D_SIZE;
long stamp = seg.lock.readLock();
try {
return new PidStateDto(
seg.integrals.get(D_LAYOUT, offset),
seg.errors.get(D_LAYOUT, offset),
seg.lambdas.get(D_LAYOUT, offset),
seg.times.get(L_LAYOUT, offset)
);
} finally {
seg.lock.unlockRead(stamp);
}
}
private String findIdByHandle(int handle) {
for (var entry : registry.entrySet()) {
if (entry.getValue() == handle) return entry.getKey();
}
return null;
}
public record PidStateDto(double integral, double lastError, double lastLambda, long updateTime) {}
public void loadAllStates() {
if (closed.get()) return;
plugin.getDatabaseManager().loadStates(snapshot -> {
int handle = getHandle(snapshot.itemId());
if (handle < 0) return;
int segId = handle >>> 16;
int slot = handle & SLOT_MASK;
Segment seg = segments[segId];
long offset = (long) slot * D_SIZE;
long stamp = seg.lock.writeLock();
try {
seg.integrals.set(D_LAYOUT, offset, snapshot.integral());
seg.errors.set(D_LAYOUT, offset, snapshot.lastError());
seg.lambdas.set(D_LAYOUT, offset, snapshot.lastLambda());
seg.times.set(L_LAYOUT, offset, snapshot.updateTime());
seg.dirty.set(B_LAYOUT, (long) slot, (byte) 0);
} finally {
seg.lock.unlockWrite(stamp);
}
});
}
}
